{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"bb504219aad64c9ea3fd5f80ae240ce9","deepnote_cell_type":"text-cell-h1","formattedRanges":[]},"source":["# Tugas Besar 1 Machine Learning"]},{"cell_type":"markdown","metadata":{"cell_id":"cccd3ddc8c7d471f8f8de7880bc8732c","deepnote_cell_type":"markdown"},"source":["## About\n","Feedforward Neural Network algorithm with rectified linear unit (ReLU) and sigmoid activation function.\n","\n","### Features\n","\n","### Usage\n","\n","### Tech stack\n","* ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)\n","\n","## Author\n","| Name | NIM |\n","| :--- | :---: |\n","| Angger Ilham Amanullah | 13521001 |\n","| Kelvin Rayhan Alkarim | 13521005 |\n","| Ditra Rizqa Amadia | 13521019 |\n","| Bernardus Willson | 13521021 |"]},{"cell_type":"markdown","metadata":{"cell_id":"fc87ca933e3c4795a4e87231e828012c","deepnote_cell_type":"separator"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"cell_id":"8cbf9e0cf0db4e89999ee957f789d882","deepnote_cell_type":"text-cell-callout","formattedRanges":[]},"source":["> Make sure required modules are imported"]},{"cell_type":"code","execution_count":271,"metadata":{"cell_id":"d288ab750b614db7a2d8ff2bdc4aa4db","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1711813803986,"source_hash":null},"outputs":[],"source":["# Modules\n","import json\n","import numpy as np\n","from graphviz import Digraph, Source\n","from IPython.display import display\n","import pickle\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"cell_id":"10c2e6e558fa4fcab00df3eaa208a157","deepnote_cell_type":"markdown"},"source":["### Classes"]},{"cell_type":"code","execution_count":272,"metadata":{"cell_id":"06cbdeb956d44a469343c389a447535e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1711813803987,"source_hash":null},"outputs":[],"source":["class Driver:\n","    @staticmethod\n","    def terminate(code):\n","        print(f\"[■] Program terminated with code {code}\")\n","        quit(code)\n","\n","    @staticmethod\n","    def load_model(model_file):\n","        try:\n","            model = json.load(open(model_file, \"r\"))\n","        except:\n","            print(f\"[✖] Error loading model from '{model_file}'\")\n","            print(\"\")\n","\n","            Driver.terminate(1)        \n","            \n","        print(f\"[✔] Successfully loaded model from '{model_file}'\")\n","        print(\"\")\n","\n","        return model"]},{"cell_type":"code","execution_count":273,"metadata":{"cell_id":"9f49d935bea74ab4a472c1c166e849c9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":39,"execution_start":1711813803988,"source_hash":null},"outputs":[],"source":["class Layer:\n","    # Initialize layer\n","    def __init__(self, id, layer, weight, input):\n","        try:\n","            self._id = id\n","            self._num_of_neuron = layer[\"number_of_neurons\"]\n","            self._activation_function = layer[\"activation_function\"]\n","            self._weight = weight\n","            self._input = input       \n","            self._input = np.insert(self._input, 0, 1) # Append bias of 1\n","            self._sigma = np.zeros(self._num_of_neuron)\n","            self._output = np.zeros(self._num_of_neuron)\n","            self._error = np.zeros(self._num_of_neuron)\n","            self._error_node_output = np.zeros(self._num_of_neuron)\n","            self._loss = 0\n","        except:\n","            print(f\"[✖] Error initialiazing layer\")\n","            print(\"\")\n","\n","            Driver.terminate(1)\n","\n","    # Calculate sigma\n","    def _calculate_sigma(self, i):\n","        for j in range(len(self._input)):\n","            self._sigma[i] += self._input[j] * self._weight[j][i]\n","\n","    # Calculate activation\n","    def _calculate_activation(self, i):\n","        if self._activation_function == 'relu':\n","            self._output[i] = max(0, self._sigma[i])\n","        elif self._activation_function == 'sigmoid':\n","            self._output[i] = 1 / (1 + np.exp(-self._sigma[i]))\n","        elif self._activation_function == 'linear':\n","            self._output[i] = self._sigma[i]\n","        elif self._activation_function == 'softmax':\n","            exp_values = np.exp(self._sigma - np.max(self._sigma))\n","            self._output = exp_values / np.sum(exp_values)\n","\n","    # Calculate error\n","    def _calculate_error(self, target, i, isOutput):\n","        if isOutput:\n","            self._error[i] = target[i] - self._output[i]\n","        else:\n","            for j in range(len(target)):\n","                self._error[i] += target[j] * self._weight[i+1][j]\n","\n","    # Calculate ENO\n","    def _calculate_derivative(self, i):\n","        if self._activation_function == 'relu':\n","            self._error_node_output[i] = self._error[i] if self._sigma[i] > 0 else 0\n","        elif self._activation_function == 'sigmoid':\n","            self._error_node_output[i] = self._error[i] * self._sigma[i] * (1 - self._sigma[i])\n","        elif self._activation_function == 'linear':\n","            self._error_node_output[i] = self._error[i]\n","        elif self._activation_function == 'softmax':\n","            pass\n","\n","    # Calculate forward\n","    def _calculate_forward(self):\n","        print(f\"[●] Building layer {self._id}\")\n","\n","        # For each neuron, calculate its activation\n","        for i in range(self._num_of_neuron):\n","            self._calculate_sigma(i)\n","            self._calculate_activation(i)\n","\n","        print(f\"[✔] Successfully built layer {self._id}\")\n","        print(f\"Number of neurons: {self._num_of_neuron}\")\n","        print(f\"Activation function: {self._activation_function}\")\n","        for i in range(len(self._output)):\n","            print(f\"h{self._id}{i}: {self._output[i]}\")\n","        print(\"\")\n","        \n","        return self._output\n","\n","    # Calculate Error Node Output\n","    def _calculate_error_node_ouput(self, target, isOutput):\n","        print(f\"[●] Calculating Error Node Output for layer {self._id}\")\n","\n","        # For each output, calculate its error node output\n","        for i in range(self._num_of_neuron):\n","            self._calculate_error(target, i, isOutput)\n","            self._calculate_derivative(i)\n","\n","        print(f\"[✔] Successfully calculated Error Node Output for layer {self._id}\")\n","        for i in range(len(self._error_node_output)):\n","            print(f\"e{self._id}{i}: {self._error_node_output[i]}\")\n","        print(\"\")\n","\n","        return self._error_node_output\n","\n","    def _calculate_loss(self, target):\n","        print(f\"[●] Calculating Loss for layer {self._id}\")\n","\n","        for i in range(self._num_of_neuron):\n","            self._loss += (target[i] - self._output[i]) ** 2\n","\n","        self._loss /= len(target)\n","\n","        print(f\"[✔] Successfully calculated Loss for layer {self._id}\")\n","        print(f\"Loss: {self._loss}\")\n","        print(\"\")\n","\n","        return self._loss\n","        "]},{"cell_type":"code","execution_count":274,"metadata":{"cell_id":"b19fca533a574742a2de0b3b4d62cf61","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":264,"execution_start":1711813804006,"source_hash":null},"outputs":[],"source":["class FFNN:\n","    # Initialize model\n","    def __init__(self, model):\n","        try:\n","            self._layers = model[\"case\"][\"model\"][\"layers\"]\n","            self._weights = model[\"case\"][\"initial_weights\"]\n","            self._inputs = model[\"case\"][\"input\"]\n","            self._targets = model[\"case\"][\"target\"]\n","            self._layer_objects = []\n","\n","            self._learning_rate = model[\"case\"][\"learning_parameters\"][\"learning_rate\"]\n","            self._batch_size = model[\"case\"][\"learning_parameters\"][\"batch_size\"]\n","            self._max_iteration = model[\"case\"][\"learning_parameters\"][\"max_iteration\"]\n","            self._error_threshold = model[\"case\"][\"learning_parameters\"][\"error_threshold\"]\n","\n","            self._error_node_output = []\n","            self._loss = 0\n","            \n","            self._outputs = []\n","            self._outputs\n","            self._expect = model[\"case\"][\"expect\"]\n","        except:\n","            print(f\"[✖] Error initialiazing model\")\n","            print(\"\")\n","\n","            Driver.terminate(1)\n","        \n","        print(f\"[✔] Successfully initialized model\")\n","        print(f\"Number of features: {model['case']['model']['input_size']}\")\n","        print(f\"Number of layers: {len(self._layers)}\")\n","        print(f\"Number of data: {len(self._inputs)}\")\n","        print(\"\")\n","\n","    # Assert the output with the expected output\n","    def test(self):\n","        print(f\"[●] Asserting output =======================================\")\n","\n","        passed_output = 0\n","        for i in range(len(self._inputs)):\n","            if (np.all(self._expect['output'][i] < self._outputs[i] + self._expect['max_sse']) or np.all(self._expect['output'][i] > self._outputs[i] - self._expect['max_sse'])):\n","                passed_output += 1\n","\n","        print(f\"Test status: {'FAIL' if passed_output != len(self._inputs) else 'PASS'}\")\n","        print(f\"Test result: {passed_output}/{len(self._inputs)}\")\n","        print(\"\")\n","    \n","    # Build the network\n","    def build(self):\n","        # Loop until max epoch\n","        for epoch in range(self._max_iteration):\n","            print(f\"[●] Epoch {epoch + 1} ========================================\")\n","\n","            # Split data into batches\n","            for batch_start in range(0, len(self._inputs), self._batch_size):\n","                X_batch = self._inputs[batch_start:batch_start + self._batch_size]\n","                y_batch = self._targets[batch_start:batch_start + self._batch_size]\n","\n","                self._outputs = []\n","                self._error_node_output = []\n","                self._layer_objects = []\n","\n","                print(f\"[●] Building batch {batch_start + 1}\")\n","\n","                # For each data in batch, calculate output\n","                for i in range(len(X_batch)):\n","                    _in = X_batch[i]\n","                    layers = []\n","\n","                    # Feed forward\n","                    for j in range(len(self._layers)):\n","                        \n","                        # Create layer\n","                        layer = Layer(j, self._layers[j], self._weights[j], _in)\n","\n","                        # Calculate forward\n","                        _in = layer._calculate_forward()\n","\n","                        # Calculate Loss\n","                        loss = layer._calculate_loss(y_batch[i])\n","\n","                        layers.append(layer)           \n","                        self._outputs.append(_in)\n","                    \n","                    self._layer_objects.append(layers)\n","                    self._loss += loss\n","                    print(f\"[✔] Successfully evaluated data {i + 1}\")\n","\n","                # Calculate Error Node Output\n","                for i in range(len(X_batch)):\n","                    for j in range(len(self._layers) - 1, -1, -1):\n","                        print(f\"[●] Calculating Error Node Output for data {i + 1} in layer {j}\")\n","                        print(self._layer_objects[i][j]._output)\n","                        if (j == len(self._layers) - 1):\n","                            self._error_node_output.append(self._layer_objects[i][j]._calculate_error_node_ouput(y_batch[i], True))\n","                        else:\n","                            self._error_node_output.append(self._layer_objects[i][j]._calculate_error_node_ouput(self._layer_objects[i][j + 1]._error_node_output, False))\n","\n","                # Update weights\n","                m = len(self._layers) - 1\n","                for i in range(len(X_batch)):\n","                    for j in range(len(self._layers)):\n","                        for k in range(len(self._weights[j])):\n","                            for l in range(len(self._weights[j][k])):\n","                                if k == 0:\n","                                    self._weights[j][k][l] += self._learning_rate * self._error_node_output[m][l]\n","                                else:\n","                                    self._weights[j][k][l] += self._learning_rate * self._error_node_output[m][l] * X_batch[i][k - 1]\n","                        m -= 1\n","\n","                # Loss threshold\n","                self._loss /= len(X_batch)\n","                if self._loss <= self._error_threshold:\n","                    print(f\"[✔] Loss threshold reached\")\n","                    return\n","\n","                # print weights\n","                print(self._weights)"]},{"cell_type":"code","execution_count":275,"metadata":{"cell_id":"516ba36dce3345e78882c74b46308a0b","deepnote_cell_type":"input-file","deepnote_to_be_reexecuted":false,"deepnote_variable_name":"model_file","deepnote_variable_value":"file_input_uploads/multilayer-20240330-154837.json","execution_millis":264,"execution_start":1711813804007,"source_hash":null},"outputs":[],"source":["model_file = 'models/relu.json'"]},{"cell_type":"code","execution_count":276,"metadata":{"cell_id":"00e313cbf76b4aab826f4ebebef495e3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":281,"execution_start":1711813804008,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["[✔] Successfully loaded model from 'models/relu.json'\n","\n","[✖] Error initialiazing model\n","\n","[■] Program terminated with code 1\n","[✔] Successfully initialized model\n","Number of features: 2\n","Number of layers: 1\n","Number of data: 2\n","\n","[●] Epoch 1 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 3\n","Activation function: relu\n","h00: 0.04999999999999993\n","h01: 1.1\n","h02: 0.0\n","\n","[●] Calculating Loss for layer 0\n","[✔] Successfully calculated Loss for layer 0\n","Loss: 0.007500000000000009\n","\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 3\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 1.5\n","\n","[●] Calculating Loss for layer 0\n","[✔] Successfully calculated Loss for layer 0\n","Loss: 0.09000000000000001\n","\n","[✔] Successfully evaluated data 2\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.05 1.1  0.  ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.05000000000000007\n","e01: -0.10000000000000009\n","e02: 0.0\n","\n","[●] Calculating Error Node Output for data 2 in layer 0\n","[0.  0.  1.5]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: -0.5\n","\n","[[[0.10500000000000001, 0.19, 0.25], [0.395, -0.49, 0.575], [0.7025, 0.795, -0.85]]]\n"]}],"source":["# Input\n","model_json = Driver.load_model(model_file)\n","\n","# Initialize FFNN\n","model = FFNN(model_json)\n","\n","# Build FNN\n","model.build()\n","\n","# Test the output\n","# model.test()\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ad693be4-3a1e-4be5-9f4f-9f4a320647d1' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"61f060aabad042bcb878ee344004af04","deepnote_persisted_session":{"createdAt":"2024-03-30T06:15:23.462Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
