{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"bb504219aad64c9ea3fd5f80ae240ce9","deepnote_cell_type":"text-cell-h1","formattedRanges":[]},"source":["# Tugas Besar 1 Machine Learning"]},{"cell_type":"markdown","metadata":{"cell_id":"cccd3ddc8c7d471f8f8de7880bc8732c","deepnote_cell_type":"markdown"},"source":["## About\n","Feedforward Neural Network algorithm with rectified linear unit (ReLU) and sigmoid activation function.\n","\n","### Features\n","\n","### Usage\n","\n","### Tech stack\n","* ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)\n","\n","## Author\n","| Name | NIM |\n","| :--- | :---: |\n","| Angger Ilham Amanullah | 13521001 |\n","| Kelvin Rayhan Alkarim | 13521005 |\n","| Ditra Rizqa Amadia | 13521019 |\n","| Bernardus Willson | 13521021 |"]},{"cell_type":"markdown","metadata":{"cell_id":"fc87ca933e3c4795a4e87231e828012c","deepnote_cell_type":"separator"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"cell_id":"8cbf9e0cf0db4e89999ee957f789d882","deepnote_cell_type":"text-cell-callout","formattedRanges":[]},"source":["> Make sure required modules are imported"]},{"cell_type":"code","execution_count":281,"metadata":{"cell_id":"d288ab750b614db7a2d8ff2bdc4aa4db","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1711813803986,"source_hash":null},"outputs":[],"source":["# Modules\n","import json\n","import numpy as np\n","from graphviz import Digraph, Source\n","from IPython.display import display\n","import pickle\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"cell_id":"10c2e6e558fa4fcab00df3eaa208a157","deepnote_cell_type":"markdown"},"source":["### Classes"]},{"cell_type":"code","execution_count":282,"metadata":{"cell_id":"06cbdeb956d44a469343c389a447535e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1711813803987,"source_hash":null},"outputs":[],"source":["class Driver:\n","    @staticmethod\n","    def terminate(code):\n","        print(f\"[■] Program terminated with code {code}\")\n","        quit(code)\n","\n","    @staticmethod\n","    def load_model(model_file):\n","        try:\n","            model = json.load(open(model_file, \"r\"))\n","        except:\n","            print(f\"[✖] Error loading model from '{model_file}'\")\n","            print(\"\")\n","\n","            Driver.terminate(1)        \n","            \n","        print(f\"[✔] Successfully loaded model from '{model_file}'\")\n","        print(\"\")\n","\n","        return model"]},{"cell_type":"code","execution_count":283,"metadata":{"cell_id":"9f49d935bea74ab4a472c1c166e849c9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":39,"execution_start":1711813803988,"source_hash":null},"outputs":[],"source":["class Layer:\n","    # Initialize layer\n","    def __init__(self, id, layer, weight, input):\n","        try:\n","            self._id = id\n","            self._num_of_neuron = layer[\"number_of_neurons\"]\n","            self._activation_function = layer[\"activation_function\"]\n","            self._weight = weight\n","            self._input = input       \n","            self._input = np.insert(self._input, 0, 1) # Append bias of 1\n","            self._sigma = np.zeros(self._num_of_neuron)\n","            self._output = np.zeros(self._num_of_neuron)\n","            self._error = np.zeros(self._num_of_neuron)\n","            self._error_node_output = np.zeros(self._num_of_neuron)\n","            self._loss = 0\n","        except:\n","            print(f\"[✖] Error initialiazing layer\")\n","            print(\"\")\n","\n","            Driver.terminate(1)\n","\n","    # Calculate sigma\n","    def _calculate_sigma(self, i):\n","        for j in range(len(self._input)):\n","            self._sigma[i] += self._input[j] * self._weight[j][i]\n","\n","    # Calculate activation\n","    def _calculate_activation(self, i):\n","        if self._activation_function == 'relu':\n","            self._output[i] = max(0, self._sigma[i])\n","        elif self._activation_function == 'sigmoid':\n","            self._output[i] = 1 / (1 + np.exp(-self._sigma[i]))\n","        elif self._activation_function == 'linear':\n","            self._output[i] = self._sigma[i]\n","        elif self._activation_function == 'softmax':\n","            exp_values = np.exp(self._sigma - np.max(self._sigma))\n","            self._output = exp_values / np.sum(exp_values)\n","\n","    # Calculate error\n","    def _calculate_error(self, target, i, weight):\n","        if weight == None:\n","            self._error[i] = target[i] - self._output[i]\n","        else:\n","            for j in range(len(target)):\n","                self._error[i] += target[j] * weight[i + 1][j]\n","\n","    # Calculate ENO\n","    def _calculate_derivative(self, i):\n","        if self._activation_function == 'relu':\n","            self._error_node_output[i] = self._error[i] if self._sigma[i] > 0 else 0\n","        elif self._activation_function == 'sigmoid':\n","            self._error_node_output[i] = self._error[i] * (1 / (1 + np.exp(-self._sigma[i]))) * (1 - (1 / (1 + np.exp(-self._sigma[i]))))\n","        elif self._activation_function == 'linear':\n","            self._error_node_output[i] = self._error[i]\n","        elif self._activation_function == 'softmax':\n","            self._error_node_output[i] = self._error[i]\n","\n","    # Calculate forward\n","    def _calculate_forward(self):\n","        print(f\"[●] Building layer {self._id}\")\n","\n","        # For each neuron, calculate its activation\n","        for i in range(self._num_of_neuron):\n","            self._calculate_sigma(i)\n","            self._calculate_activation(i)\n","\n","        print(f\"[✔] Successfully built layer {self._id}\")\n","        print(f\"Number of neurons: {self._num_of_neuron}\")\n","        print(f\"Activation function: {self._activation_function}\")\n","        for i in range(len(self._output)):\n","            print(f\"h{self._id}{i}: {self._output[i]}\")\n","        print(\"\")\n","        \n","        return self._output\n","\n","    # Calculate Error Node Output\n","    def _calculate_error_node_ouput(self, target, weight):\n","        print(f\"[●] Calculating Error Node Output for layer {self._id}\")\n","\n","        # For each output, calculate its error node output\n","        for i in range(self._num_of_neuron):\n","            self._calculate_error(target, i, weight)\n","            self._calculate_derivative(i)\n","\n","        print(f\"[✔] Successfully calculated Error Node Output for layer {self._id}\")\n","        for i in range(len(self._error_node_output)):\n","            print(f\"e{self._id}{i}: {self._error_node_output[i]}\")\n","        print(\"\")\n","\n","        return self._error_node_output\n","\n","    def _calculate_loss(self, target, isSoftmax):\n","        print(f\"[●] Calculating Loss for layer {self._id}\")\n","\n","        if isSoftmax:\n","            print(f\"Output log: {np.log(self._output)}\")\n","            self._loss = -np.sum(target * np.log(self._output))\n","        else:\n","            for i in range(self._num_of_neuron):\n","                self._loss += (target[i] - self._output[i]) ** 2\n","\n","            self._loss /= len(target)\n","\n","        print(f\"[✔] Successfully calculated Loss for layer {self._id}\")\n","        print(f\"Loss: {self._loss}\")\n","        print(\"\")\n","\n","        return self._loss\n","        "]},{"cell_type":"code","execution_count":284,"metadata":{"cell_id":"b19fca533a574742a2de0b3b4d62cf61","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":264,"execution_start":1711813804006,"source_hash":null},"outputs":[],"source":["class FFNN:\n","    # Initialize model\n","    def __init__(self, model):\n","        try:\n","            self._layers = model[\"case\"][\"model\"][\"layers\"]\n","            self._weights = model[\"case\"][\"initial_weights\"]\n","            self._inputs = model[\"case\"][\"input\"]\n","            self._targets = model[\"case\"][\"target\"]\n","            self._layer_objects = []\n","\n","            self._learning_rate = model[\"case\"][\"learning_parameters\"][\"learning_rate\"]\n","            self._batch_size = model[\"case\"][\"learning_parameters\"][\"batch_size\"]\n","            self._max_iteration = model[\"case\"][\"learning_parameters\"][\"max_iteration\"]\n","            self._error_threshold = model[\"case\"][\"learning_parameters\"][\"error_threshold\"]\n","\n","            self._error_node_output = []\n","            self._loss = 0\n","            \n","            self._outputs = []\n","            self._outputs\n","            self._expect = model[\"case\"][\"expect\"]\n","        except:\n","            print(f\"[✖] Error initialiazing model\")\n","            print(\"\")\n","\n","            Driver.terminate(1)\n","        \n","        print(f\"[✔] Successfully initialized model\")\n","        print(f\"Number of features: {model['case']['model']['input_size']}\")\n","        print(f\"Number of layers: {len(self._layers)}\")\n","        print(f\"Number of data: {len(self._inputs)}\")\n","        print(\"\")\n","\n","    # Assert the output with the expected output\n","    def test(self):\n","        print(f\"[●] Asserting output =======================================\")\n","\n","        passed_output = 0\n","        for i in range(len(self._inputs)):\n","            if (np.all(self._expect['output'][i] < self._outputs[i] + self._expect['max_sse']) or np.all(self._expect['output'][i] > self._outputs[i] - self._expect['max_sse'])):\n","                passed_output += 1\n","\n","        print(f\"Test status: {'FAIL' if passed_output != len(self._inputs) else 'PASS'}\")\n","        print(f\"Test result: {passed_output}/{len(self._inputs)}\")\n","        print(\"\")\n","    \n","    # Build the network\n","    def build(self):\n","        # Loop until max epoch\n","        for epoch in range(self._max_iteration):\n","            print(f\"[●] Epoch {epoch + 1} ========================================\")\n","\n","            # Split data into batches\n","            for batch_start in range(0, len(self._inputs), self._batch_size):\n","                X_batch = self._inputs[batch_start:batch_start + self._batch_size]\n","                y_batch = self._targets[batch_start:batch_start + self._batch_size]\n","\n","                self._outputs = []\n","                self._error_node_output = []\n","                self._layer_objects = []\n","                self._loss = 0\n","\n","                print(f\"[●] Building batch {batch_start + 1}\")\n","\n","                # For each data in batch, calculate output\n","                for i in range(len(X_batch)):\n","                    _in = X_batch[i]\n","                    layers = []\n","\n","                    # Feed forward\n","                    for j in range(len(self._layers)):\n","                        \n","                        # Create layer\n","                        layer = Layer(j, self._layers[j], self._weights[j], _in)\n","\n","                        # Calculate forward\n","                        _in = layer._calculate_forward()\n","\n","                        layers.append(layer)           \n","                        self._outputs.append(_in)\n","                    \n","                    # Calculate Loss\n","                    loss = layer._calculate_loss(y_batch[i], self._layers[-1][\"activation_function\"] == 'softmax')\n","                    self._loss += loss\n","                    \n","                    self._layer_objects.append(layers)\n","                    print(f\"[✔] Successfully evaluated data {i + 1}\")\n","\n","                # Calculate Error Node Output\n","                for i in range(len(X_batch)):\n","                    for j in range(len(self._layers) - 1, -1, -1):\n","                        print(f\"[●] Calculating Error Node Output for data {i + 1} in layer {j}\")\n","                        print(self._layer_objects[i][j]._output)\n","                        if (j == len(self._layers) - 1):\n","                            self._error_node_output.append(self._layer_objects[i][j]._calculate_error_node_ouput(y_batch[i], None))\n","                        else:\n","                            self._error_node_output.append(self._layer_objects[i][j]._calculate_error_node_ouput(self._layer_objects[i][j + 1]._error_node_output, self._layer_objects[i][j + 1]._weight))\n","\n","                # Update weights\n","                m = len(self._layers) - 1\n","                for i in range(len(X_batch)):\n","                    for j in range(len(self._layers)):\n","                        for k in range(len(self._weights[j])):\n","                            for l in range(len(self._weights[j][k])):\n","                                if k == 0:\n","                                    self._weights[j][k][l] += self._learning_rate * self._error_node_output[m][l]\n","                                else:\n","                                    if (j == 0):\n","                                        self._weights[j][k][l] += self._learning_rate * self._error_node_output[m][l] * X_batch[i][k - 1]\n","                                    else:\n","                                        self._weights[j][k][l] += self._learning_rate * self._error_node_output[m][l] * self._layer_objects[i][j - 1]._output[k - 1]\n","                        m -= 1\n","\n","                # Loss threshold\n","                self._loss /= len(X_batch)\n","                if self._loss <= self._error_threshold:\n","                    print(f\"[✔] Loss threshold reached\")\n","                    return\n","\n","                # print weights\n","                print(self._weights)"]},{"cell_type":"code","execution_count":285,"metadata":{"cell_id":"516ba36dce3345e78882c74b46308a0b","deepnote_cell_type":"input-file","deepnote_to_be_reexecuted":false,"deepnote_variable_name":"model_file","deepnote_variable_value":"file_input_uploads/multilayer-20240330-154837.json","execution_millis":264,"execution_start":1711813804007,"source_hash":null},"outputs":[],"source":["model_file = 'models/softmax_two_layer.json'"]},{"cell_type":"code","execution_count":286,"metadata":{"cell_id":"00e313cbf76b4aab826f4ebebef495e3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":281,"execution_start":1711813804008,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["[✔] Successfully loaded model from 'models/softmax_two_layer.json'\n","\n","[✖] Error initialiazing model\n","\n","[■] Program terminated with code 1\n","[✔] Successfully initialized model\n","Number of features: 2\n","Number of layers: 2\n","Number of data: 8\n","\n","[●] Epoch 1 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.595\n","h02: 0.0\n","h03: 0.003000000000000058\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5868503570425038\n","h11: 0.4131496429574962\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.53298542 -0.88394542]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.883945420031139\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.58685036 0.41314964]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5868503570425038\n","e11: 0.5868503570425039\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.    0.595 0.    0.003]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.12910707854935083\n","e02: 0.0\n","e03: -0.011737007140850075\n","\n","[[[0.1, -0.1129107078549351, 0.1, -0.10117370071408502], [-0.1, 0.048486275658809024, -0.1, 0.09531693415080082], [0.1, 0.06178430474939216, -0.1, -0.10347415411369162]], [[0.06131496429574962, -0.041314964295749615], [-0.12, 0.1], [0.08508240375597102, -0.06508240375597102], [-0.12, 0.1], [0.019823944892887246, 0.0001760551071127546]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.45099999999999996\n","h01: 0.025660089725608543\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5018157847740381\n","h11: 0.49818421522596196\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.68952219 -0.69678536]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6895221892391775\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50181578 0.49818422]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4981842152259619\n","e11: -0.49818421522596196\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.451      0.02566009 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.10960052734971162\n","e01: 0.07480973678489447\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.08903994726502884, -0.10542973417644565, 0.1, -0.10117370071408502], [-0.09221836255817048, 0.04317478434708152, -0.1, 0.09531693415080082], [0.06931185234208075, 0.0827310310491626, -0.1, -0.10347415411369162]], [[0.11113338581834581, -0.09113338581834582], [-0.09753189189330912, 0.07753189189330913], [0.08636074892222903, -0.06636074892222903], [-0.12, 0.1], [0.019823944892887246, 0.0001760551071127546]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.29926819781296693\n","h01: 0.0\n","h02: 0.36300000000000004\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5174967899863836\n","h11: 0.4825032100136164\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.65875196 -0.72876771]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7287677053472653\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51749679 0.48250321]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5174967899863836\n","e11: 0.5174967899863836\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.2992682 0.        0.363     0.       ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.09059494615244525\n","e01: 0.0\n","e02: 0.1138492937970044\n","e03: 0.0\n","\n","[[[0.09809944188027336, -0.10542973417644565, 0.11138492937970045, -0.10117370071408502], [-0.11423293447321467, 0.04317478434708152, -0.12766537839267209, 0.09531693415080082], [0.06749995341903184, 0.0827310310491626, -0.1022769858759401, -0.10347415411369162]], [[0.05938370681970745, -0.03938370681970746], [-0.11301892506463117, 0.09301892506463118], [0.08636074892222903, -0.06636074892222903], [-0.13878513347650573, 0.11878513347650574], [0.019823944892887246, 0.0001760551071127546]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.49199189533724463\n","h01: 0.029293476912905486\n","h02: 0.08598344533081431\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4949315301052815\n","h11: 0.5050684698947185\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.70333585 -0.68306127]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7033358490005912\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.49493153 0.50506847]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5050684698947185\n","e11: -0.5050684698947185\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.4919919  0.02929348 0.08598345 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.10406322170518387\n","e01: 0.07713481323632998\n","e02: -0.1300906206203317\n","e03: 0.0\n","\n","[[[0.08769311970975498, -0.09771625285281264, 0.09837586731766727, -0.10117370071408502], [-0.09446092234922973, 0.028519169832178823, -0.10294816047480906, 0.09531693415080082], [0.04023538933227366, 0.10294035211708105, -0.136360728478467, -0.10347415411369162]], [[0.10989055380917931, -0.08989055380917932], [-0.0881699656867727, 0.06816996568677271], [0.08784027007845878, -0.06784027007845878], [-0.13444238075955467, 0.11444238075955468], [0.019823944892887246, 0.0001760551071127546]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.388938906115919\n","h01: 0.0\n","h02: 0.16898627961846685\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5242101319007995\n","h11: 0.47578986809920054\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.64586266 -0.74277898]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.64586265996829\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.52421013 0.47578987]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.47578986809920054\n","e11: -0.47578986809920054\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.38893891 0.         0.16898628 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.07438495532685724\n","e01: 0.0\n","e02: -0.11841684785507801\n","e03: 0.0\n","\n","[[[0.08025462417706926, -0.09771625285281264, 0.08653418253215947, -0.10117370071408502], [-0.07526960387490056, 0.028519169832178823, -0.07239661372819893, 0.09531693415080082], [0.02959834072053308, 0.10294035211708105, -0.15329433772174317, -0.10347415411369162]], [[0.15746954061909937, -0.13746954061909938], [-0.06966464660281865, 0.04966464660281866], [0.08784027007845878, -0.06784027007845878], [-0.12640218479053017, 0.10640218479053018], [0.019823944892887246, 0.0001760551071127546]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.3310297802878449\n","h01: 0.0\n","h02: 0.37317815205031757\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5420405142630237\n","h11: 0.4579594857369763\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.61241453 -0.78097456]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7809745578702595\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.54204051 0.45795949]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5420405142630237\n","e11: 0.5420405142630237\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.33102978 0.         0.37317815 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.06468131145582678\n","e01: 0.0\n","e02: 0.12618940021039698\n","e03: 0.0\n","\n","[[[0.08672275532265193, -0.09771625285281264, 0.09915312255319916, -0.10117370071408502], [-0.09745529370424916, 0.028519169832178823, -0.1156795780003651, 0.09531693415080082], [0.02798130793413741, 0.10294035211708105, -0.1564490727270031, -0.10347415411369162]], [[0.103265489192797, -0.08326548919279701], [-0.08760780183717858, 0.06760780183717859], [0.08784027007845878, -0.06784027007845878], [-0.14662995253543806, 0.12662995253543807], [0.019823944892887246, 0.0001760551071127546]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.3259544751248864\n","h03: 0.24643132802082665\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5255533537632021\n","h11: 0.47444664623679794\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.64330356 -0.74560611]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6433035642980629\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.52555335 0.47444665]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4744466462367979\n","e11: -0.47444664623679794\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.         0.32595448 0.24643133]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: -0.12964724551186296\n","e03: 0.009321875414490944\n","\n","[[[0.08672275532265193, -0.09771625285281264, 0.08618839800201286, -0.10024151317263592], [-0.09745529370424916, 0.028519169832178823, -0.13058901123422934, 0.09638894982346728], [0.02798130793413741, 0.10294035211708105, -0.12663020625927462, -0.10561818545902454]], [[0.1507101538164768, -0.13071015381647683], [-0.08760780183717858, 0.06760780183717859], [0.08784027007845878, -0.06784027007845878], [-0.13116515178055024, 0.11116515178055025], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.3794900088328424\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.584311856528385\n","h11: 0.41568814347161503\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.53732044 -0.87781995]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.8778199549690906\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.58431186 0.41568814]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.584311856528385\n","e11: 0.5843118565283849\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.37949001 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.09096598544443028\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.08672275532265193, -0.10681285139725567, 0.08618839800201286, -0.10024151317263592], [-0.09745529370424916, -0.010414271938037338, -0.13058901123422934, 0.09638894982346728], [0.02798130793413741, 0.07155708713875261, -0.12663020625927462, -0.10561818545902454]], [[0.09227896816363829, -0.07227896816363832], [-0.08760780183717858, 0.06760780183717859], [0.06566621891894964, -0.04566621891894964], [-0.13116515178055024, 0.11116515178055025], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Epoch 2 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0634431815006831\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.542800303844145\n","h11: 0.457199696155855\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.61101379 -0.78263501]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7826350116376976\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5428003 0.4571997]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.542800303844145\n","e11: 0.542800303844145\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.06344318 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.060431281086121114\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.08672275532265193, -0.11285597950586779, 0.08618839800201286, -0.10024151317263592], [-0.09745529370424916, -0.03452635309139966, -0.13058901123422934, 0.09638894982346728], [0.02798130793413741, 0.05366942793726076, -0.12663020625927462, -0.10561818545902454]], [[0.03799893777922378, -0.017998937779223817], [-0.08760780183717858, 0.06760780183717859], [0.06222252109940864, -0.04222252109940864], [-0.13116515178055024, 0.11116515178055025], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.2342636760682536\n","h01: 0.06193212941335609\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5065258797864786\n","h11: 0.4934741202135215\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.68017986 -0.70628486]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.680179861265101\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50652588 0.49347412]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.49347412021352144\n","e11: -0.4934741202135215\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.23426368 0.06193213 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.07659488346661403\n","e01: 0.05154092530972548\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.07906326697599053, -0.10770188697489524, 0.08618839800201286, -0.10024151317263592], [-0.09201705697811956, -0.03818575878839017, -0.13058901123422934, 0.09638894982346728], [0.006534740563485481, 0.0681008870239839, -0.12663020625927462, -0.10561818545902454]], [[0.08734634980057593, -0.06734634980057597], [-0.07604749569260189, 0.0560474956926019], [0.06527871140692922, -0.045278711406929226], [-0.13116515178055024, 0.11116515178055025], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.3013577673201239\n","h01: 0.0\n","h02: 0.4288457365530451\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5027406051544011\n","h11: 0.49725939484559895\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.68768094 -0.69864347]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6986434678205063\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50274061 0.49725939]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5027406051544011\n","e11: 0.502740605154401\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.30135777 0.         0.42884574 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.06640951590686274\n","e01: 0.0\n","e02: 0.12182928345955737\n","e03: 0.0\n","\n","[[[0.0857042185666768, -0.10770188697489524, 0.09837132634796861, -0.10024151317263592], [-0.1081545693434872, -0.03818575878839017, -0.16019352711490178, 0.09638894982346728], [0.005206550245348226, 0.0681008870239839, -0.12906679192846576, -0.10561818545902454]], [[0.03707228928513581, -0.017072289285135864], [-0.09119797432365172, 0.07119797432365173], [0.06527871140692922, -0.045278711406929226], [-0.1527249682918065, 0.13272496829180652], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.30483906196211485\n","h01: 0.1432753787258839\n","h02: 0.06458403301370169\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5005111494256128\n","h11: 0.49948885057438713\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.6921254 -0.69417  ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6921254039003301\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50051115 0.49948885]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4994888505743872\n","e11: -0.49948885057438713\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.30483906 0.14327538 0.06458403 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.08111496572777879\n","e01: 0.05522220004376068\n","e02: -0.1425790607206806\n","e03: 0.0\n","\n","[[[0.07759272199389892, -0.10217966697051918, 0.08411342027590055, -0.10024151317263592], [-0.09274272585520923, -0.0486779767967047, -0.13310350557797246, 0.09638894982346728], [-0.01604557077532982, 0.0825691034354492, -0.16642250583728407, -0.10561818545902454]], [[0.08702117434257453, -0.06702117434257458], [-0.0759716030566886, 0.055971603056688614], [0.07243515683046939, -0.0524351568304694], [-0.1494990678502593, 0.1294990678502593], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.29392378849161716\n","h01: 0.1414833310776713\n","h02: 0.18953628131975328\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5200012961224163\n","h11: 0.47999870387758364\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.65392397 -0.73397188]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6539239748666621\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5200013 0.4799987]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4799987038775837\n","e11: -0.47999870387758364\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.29392379 0.14148333 0.18953628 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.06333256791987393\n","e01: 0.059937588710037945\n","e02: -0.13391874352051114\n","e03: 0.0\n","\n","[[[0.07125946520191154, -0.09618590809951538, 0.07072154592384944, -0.10024151317263592], [-0.07640292333188176, -0.0641418746838945, -0.09855246974968057, 0.09638894982346728], [-0.025102127987871793, 0.09114017862098463, -0.18557288616071715, -0.10561818545902454]], [[0.1350210447303329, -0.11502104473033295], [-0.06186329930521207, 0.041863299305212084], [0.07922633838422592, -0.059226338384225925], [-0.14040135091313344, 0.12040135091313343], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.3395970242272339\n","h01: 0.1010356774109966\n","h02: 0.45514973870543307\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5274975337871812\n","h11: 0.4725024662128187\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.63961109 -0.74971231]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7497123125639321\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.52749753 0.47250247]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5274975337871812\n","e11: 0.5274975337871812\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.33959702 0.10103568 0.45514974 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0547155249551316\n","e01: -0.0730334455415921\n","e02: 0.13757278201838935\n","e03: 0.0\n","\n","[[[0.0767310176974247, -0.10348925265367459, 0.08447882412568837, -0.10024151317263592], [-0.0951703483914919, -0.0390914028631284, -0.14573993398198812, 0.09638894982346728], [-0.026470016111750084, 0.09296601475952443, -0.18901220571117688, -0.10561818545902454]], [[0.08227129135161479, -0.06227129135161483], [-0.07977695858134522, 0.05977695858134524], [0.07389673131834414, -0.05389673131834413], [-0.16441038738023303, 0.144410387380233], [0.03151579660360339, -0.011515796603603393]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.028166154104234217\n","h01: 0.0\n","h02: 0.35160597318210884\n","h03: 0.25352760568010785\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5107329393501485\n","h11: 0.48926706064985154\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.67190845 -0.7148468 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.67190844897466\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51073294 0.48926706]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4892670606498515\n","e11: -0.48926706064985154\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.02816615 0.         0.35160597 0.25352761]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.06827913485236242\n","e01: 0.0\n","e02: -0.1510958327346631\n","e03: 0.021053941123570178\n","\n","[[[0.06990310421218845, -0.10348925265367459, 0.06936924085222206, -0.0981361190602789], [-0.10302244889951358, -0.0390914028631284, -0.16311595474647436, 0.09881015305267785], [-0.010765815095706729, 0.09296601475952443, -0.15426016418220437, -0.11046059191744569]], [[0.13119799741659993, -0.11119799741659998], [-0.07839888143850628, 0.0583988814385063], [0.07389673131834414, -0.05389673131834413], [-0.14720746527965894, 0.12720746527965893], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.04993229401249516\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5618754598840778\n","h11: 0.43812454011592217\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.57647506 -0.82525207]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.8252520708579197\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.56187546 0.43812454]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5618754598840778\n","e11: 0.5618754598840778\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.04993229 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.07180401058916794\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.06990310421218845, -0.11066965371259138, 0.06936924085222206, -0.0981361190602789], [-0.10302244889951358, -0.06982351939529229, -0.16311595474647436, 0.09881015305267785], [-0.010765815095706729, 0.06819363110626149, -0.15426016418220437, -0.11046059191744569]], [[0.07501045142819215, -0.0550104514281922], [-0.07839888143850628, 0.0583988814385063], [0.07109115825221037, -0.05109115825221036], [-0.14720746527965894, 0.12720746527965893], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Epoch 3 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5324595100812821\n","h11: 0.46754048991871794\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.63024842 -0.76026932]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7602693245519743\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.53245951 0.46754049]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5324595100812821\n","e11: 0.5324595100812821\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.06990310421218845, -0.11066965371259138, 0.06936924085222206, -0.0981361190602789], [-0.10302244889951358, -0.06982351939529229, -0.16311595474647436, 0.09881015305267785], [-0.010765815095706729, 0.06819363110626149, -0.15426016418220437, -0.11046059191744569]], [[0.02176450042006394, -0.0017645004200639858], [-0.07839888143850628, 0.0583988814385063], [0.07109115825221037, -0.05109115825221036], [-0.14720746527965894, 0.12720746527965893], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.11290476066286424\n","h01: 0.1298472121555983\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5059869426855722\n","h11: 0.49401305731442785\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.68124441 -0.70519333]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6812444149968504\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50598694 0.49401306]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4940130573144278\n","e11: -0.49401305731442785\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.11290476 0.12984721 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.06757988107264712\n","e01: 0.06035965972610796\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.06314511610492374, -0.10463368773998058, 0.06936924085222206, -0.0981361190602789], [-0.09822427734335563, -0.07410905523584595, -0.16311595474647436, 0.09881015305267785], [-0.029688181796047923, 0.08509433582957172, -0.15426016418220437, -0.11046059191744569]], [[0.07116580615150672, -0.051165806151506774], [-0.07282123883846475, 0.05282123883846477], [0.0775057800782846, -0.05750578007828459], [-0.14720746527965894, 0.12720746527965893], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.30776774640848753\n","h01: 0.05843244931721074\n","h02: 0.49659304372259566\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.48882171807786917\n","h11: 0.5111782819221309\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.71575744 -0.67103686]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.671036861324178\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.48882172 0.51117828]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.48882171807786917\n","e11: 0.4888217180778691\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.30776775 0.05843245 0.49659304 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.061416771801597006\n","e01: -0.06599658279610773\n","e02: 0.13413997782222492\n","e03: 0.0\n","\n","[[[0.06928679328508344, -0.11123334601959135, 0.08278323863444455, -0.0981361190602789], [-0.11314855289114371, -0.05807188561639177, -0.19571196935727503, 0.09881015305267785], [-0.030916517232079863, 0.08641426748549388, -0.15694296373864886, -0.11046059191744569]], [[0.0222836343437198, -0.002283634343719858], [-0.08786559469529984, 0.06786559469529985], [0.0746494750516109, -0.05464947505161089], [-0.17148201176145872, 0.1514820117614587], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.2032677686302072\n","h01: 0.225508617463547\n","h02: 0.04344541541800706\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5020097038332441\n","h11: 0.497990296166756\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.68913583 -0.69717469]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6891358291321289\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5020097 0.4979903]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.49799029616675594\n","e11: -0.497990296166756\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.20326777 0.22550862 0.04344542 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.0775526211270259\n","e01: 0.06438962245595403\n","e02: -0.16083294972538478\n","e03: 0.0\n","\n","[[[0.06153153117238085, -0.10479438377399596, 0.06669994366190607, -0.0981361190602789], [-0.09841355487700879, -0.07030591388302304, -0.1651537089094519, 0.09881015305267785], [-0.05123530396736065, 0.10328434856895384, -0.19908119656669968, -0.11046059191744569]], [[0.0720826639603954, -0.05208266396039546], [-0.07774305706516858, 0.05774305706516859], [0.08587958537149365, -0.06587958537149363], [-0.1693184722323486, 0.1493184722323486], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.24217201808173777\n","h01: 0.2242914924978075\n","h02: 0.2081104015579115\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5147659577914439\n","h11: 0.4852340422085561\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.66404293 -0.72312394]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.664042932502903\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51476596 0.48523404]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.48523404220855615\n","e11: -0.4852340422085561\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.24217202 0.22429149 0.2081104  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.06574247482259328\n","e01: 0.07363871586183818\n","e02: -0.15461349255958823\n","e03: 0.0\n","\n","[[[0.054957283690121525, -0.09743051218781214, 0.051238594405947246, -0.0981361190602789], [-0.08145199637277972, -0.08930470257537729, -0.12526342782907815, 0.09881015305267785], [-0.060636477866991494, 0.1138146849371967, -0.22119092600272078, -0.11046059191744569]], [[0.12060606818125101, -0.10060606818125106], [-0.06599204634080806, 0.04599204634080808], [0.09676297212526377, -0.07676297212526376], [-0.1592202470949895, 0.13922024709498948], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.34949675071550385\n","h01: 0.18043094641143279\n","h02: 0.5361898833603655\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5133375192814765\n","h11: 0.4866624807185236\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.66682172 -0.72018445]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7201844542481634\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51333752 0.48666248]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5133375192814765\n","e11: 0.5133375192814764\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.34949675 0.18043095 0.53618988 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.057485636336167774\n","e01: -0.08907737775254158\n","e02: 0.1532007029406217\n","e03: 0.0\n","\n","[[[0.0607058473237383, -0.10633824996306629, 0.06655866470000942, -0.0981361190602789], [-0.10116956963608527, -0.05875116200625552, -0.1778112689377114, 0.09881015305267785], [-0.06207361877539569, 0.11604161938101024, -0.2250209435762363, -0.11046059191744569]], [[0.06927231625310336, -0.04927231625310342], [-0.0839330258417314, 0.06393302584173141], [0.08750077468201838, -0.06750077468201837], [-0.18674488555379293, 0.1667448855537929], [0.04392006724607349, -0.02392006724607349]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.08713016542565033\n","h01: 0.0\n","h02: 0.3796238756469848\n","h03: 0.26955491836042567\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4974386533971312\n","h11: 0.5025613466028688\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.69828304 -0.68803756]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6982830397412725\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.49743865 0.50256135]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5025613466028688\n","e11: -0.5025613466028688\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.08713017 0.         0.37962388 0.26955492]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.07431176205089046\n","e01: 0.0\n","e02: -0.17765029537816818\n","e03: 0.034093829344093114\n","\n","[[[0.05327467111864925, -0.10633824996306629, 0.048793635162192595, -0.09472673612586958], [-0.10971542227193767, -0.05875116200625552, -0.19824105290620075, 0.10273094342724856], [-0.04498191350369088, 0.11604161938101024, -0.18416137563925764, -0.1183021726665871]], [[0.11952845091339023, -0.0995284509133903], [-0.07955420051512685, 0.05955420051512686], [0.08750077468201838, -0.06750077468201837], [-0.16766645693901805, 0.14766645693901803], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.04255036351464542\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5561749066338842\n","h11: 0.44382509336611564\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.58667245 -0.81232473]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.8123247280223387\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.55617491 0.44382509]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5561749066338842\n","e11: 0.5561749066338844\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.04255036 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.08620797224565055\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.05327467111864925, -0.11495904718763135, 0.048793635162192595, -0.09472673612586958], [-0.10971542227193767, -0.09564817412739396, -0.19824105290620075, 0.10273094342724856], [-0.04498191350369088, 0.0862998689562608, -0.18416137563925764, -0.1183021726665871]], [[0.06391096025000181, -0.04391096025000186], [-0.07955420051512685, 0.05955420051512686], [0.0851342302365188, -0.06513423023651879], [-0.16766645693901805, 0.14766645693901803], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Epoch 4 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5269293960548057\n","h11: 0.4730706039451943\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.64068871 -0.74851063]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7485106332465461\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5269294 0.4730706]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5269293960548057\n","e11: 0.5269293960548057\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.05327467111864925, -0.11495904718763135, 0.048793635162192595, -0.09472673612586958], [-0.10971542227193767, -0.09564817412739396, -0.19824105290620075, 0.10273094342724856], [-0.04498191350369088, 0.0862998689562608, -0.18416137563925764, -0.1183021726665871]], [[0.011218020644521237, 0.008781979355478718], [-0.07955420051512685, 0.05955420051512686], [0.0851342302365188, -0.06513423023651879], [-0.16766645693901805, 0.14766645693901803], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.005223263121390542\n","h01: 0.19459078952034856\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5077369573615395\n","h11: 0.49226304263846055\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.67779177 -0.70874207]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6777917659780238\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50773696 0.49226304]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.49226304263846055\n","e11: -0.49226304263846055\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.00522326 0.19459079 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.06847792474772385\n","e01: 0.07397160956505472\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.046426878643876866, -0.10756188623112588, 0.048793635162192595, -0.09472673612586958], [-0.10485348961484928, -0.10090015840651284, -0.19824105290620075, 0.10273094342724856], [-0.06415573243305356, 0.10701191963447612, -0.18416137563925764, -0.1183021726665871]], [[0.06044432490836729, -0.040444324908367336], [-0.07929707857546316, 0.05929707857546316], [0.0947132156483895, -0.0747132156483895], [-0.16766645693901805, 0.14766645693901803], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.3140520048945713\n","h01: 0.1162231147698051\n","h02: 0.567351668852112\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.47455936101058355\n","h11: 0.5254406389894165\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.74536857 -0.64351806]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6435180560553803\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.47455936 0.52544064]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.47455936101058355\n","e11: 0.4745593610105835\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.314052   0.11622311 0.56735167 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.06577115465734398\n","e01: -0.08040289897450298\n","e02: 0.14964418611556618\n","e03: 0.0\n","\n","[[[0.05300399410961126, -0.11560217612857618, 0.06375805377374921, -0.09472673612586958], [-0.12083588019658387, -0.08136225395570862, -0.23460459013228335, 0.10273094342724856], [-0.06547115552620043, 0.10861997761396618, -0.18715425936156896, -0.1183021726665871]], [[0.012988388807308932, 0.007011611192691017], [-0.0942007104521492, 0.0742007104521492], [0.08919773894040765, -0.06919773894040765], [-0.1945906614828927, 0.17459066148289268], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.11105773900447544\n","h01: 0.3235704477358616\n","h02: 0.01916261549777687\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5078623799953434\n","h11: 0.4921376200046566\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.67754477 -0.70899689]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6775447736261618\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50786238 0.49213762]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.49213762000465655\n","e11: -0.4921376200046566\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.11105774 0.32357045 0.01916262 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.08287667448924382\n","e01: 0.07795237350376466\n","e02: -0.18168801763455208\n","e03: 0.0\n","\n","[[[0.04471632666068688, -0.10780693877819972, 0.045589252010294, -0.09472673612586958], [-0.10508931204362754, -0.09617320492142391, -0.20008386678171847, 0.10273094342724856], [-0.08718484424238232, 0.1290434994719525, -0.23475651998182162, -0.1183021726665871]], [[0.06220215080777459, -0.04220215080777465], [-0.08873514131647312, 0.06873514131647311], [0.10512185794566445, -0.08512185794566446], [-0.19364759708447868, 0.17364759708447866], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.19117242446663923\n","h01: 0.3248521341639661\n","h02: 0.22610380473312275\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5132605302223723\n","h11: 0.48673946977762783\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.66697171 -0.72002627]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6669717065427127\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51326053 0.48673947]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4867394697776277\n","e11: -0.48673946977762783\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.19117242 0.32485213 0.2261038  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.07664700187449344\n","e01: 0.09259912540147108\n","e02: -0.17877706806166915\n","e03: 0.0\n","\n","[[[0.03705162647323754, -0.09854702623805262, 0.027711545204127084, -0.09472673612586958], [-0.08531438556000823, -0.12006377927500345, -0.15395938322180783, 0.10273094342724856], [-0.09814536551043489, 0.14228517440436286, -0.2603216407146403, -0.1183021726665871]], [[0.11087609778553736, -0.09087609778553743], [-0.07943002486437356, 0.05943002486437356], [0.12093369349957442, -0.10093369349957443], [-0.18264223248142825, 0.16264223248142823], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.35421631032167455\n","h01: 0.2777004430741185\n","h02: 0.6208726398335881\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4999501738810193\n","h11: 0.5000498261189806\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.69324684 -0.69304753]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6930475332869385\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.49995017 0.50004983]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4999501738810193\n","e11: 0.49995017388101937\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.35421631 0.27770044 0.62087264 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.06942310600701412\n","e01: -0.11092263870875188\n","e02: 0.17262502829659482\n","e03: 0.0\n","\n","[[[0.04399393707393895, -0.10963929010892781, 0.044974048033786566, -0.09472673612586958], [-0.10912651092041407, -0.08201731419790154, -0.21316976792753986, 0.10273094342724856], [-0.09988094316061025, 0.14505824037208165, -0.2646372664220552, -0.1183021726665871]], [[0.06088108039743543, -0.04088108039743549], [-0.09713907545805499, 0.07713907545805498], [0.10705005501940025, -0.08705005501940026], [-0.21368277090570523, 0.1936827709057052], [0.05746685552153768, -0.03746685552153768]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.14822461878486634\n","h01: 0.0\n","h02: 0.40849452768784267\n","h03: 0.2955088459486166\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.484399316788817\n","h11: 0.515600683211183\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.72484568 -0.66242268]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7248456777319051\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.48439932 0.51560068]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.515600683211183\n","e11: -0.515600683211183\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.14822462 0.         0.40849453 0.29550885]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.08985793368112796\n","e01: 0.0\n","e02: -0.21003795167465694\n","e03: 0.04894788627358269\n","\n","[[[0.03500814370582615, -0.10963929010892781, 0.02397025286632087, -0.08983194749851131], [-0.11946017329374378, -0.08201731419790154, -0.2373241323701254, 0.10835995034871057], [-0.07921361841395082, 0.14505824037208165, -0.2163285375368841, -0.12956018650951112]], [[0.11244114871855374, -0.0924411487185538], [-0.08949660398663556, 0.06949660398663556], [0.10705005501940025, -0.08705005501940026], [-0.1926207651493171, 0.1726207651493171], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.03977753440773535\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5529514794453144\n","h11: 0.44704852055468564\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.59248502 -0.80508814]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.8050881431571736\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.55295148 0.44704852]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5529514794453144\n","e11: 0.5529514794453143\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.03977753 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.10732794300645306\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.03500814370582615, -0.12037208440957312, 0.02397025286632087, -0.08983194749851131], [-0.11946017329374378, -0.12795367380466344, -0.2373241323701254, 0.10835995034871057], [-0.07921361841395082, 0.10803010003485533, -0.2163285375368841, -0.12956018650951112]], [[0.05714600077402229, -0.037146000774022365], [-0.08949660398663556, 0.06949660398663556], [0.10485055036945583, -0.08485055036945585], [-0.1926207651493171, 0.1726207651493171], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Epoch 5 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5235555503090409\n","h11: 0.4764444496909591\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.64711214 -0.74140414]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7414041425559107\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.52355555 0.47644445]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5235555503090409\n","e11: 0.5235555503090409\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.03500814370582615, -0.12037208440957312, 0.02397025286632087, -0.08983194749851131], [-0.11946017329374378, -0.12795367380466344, -0.2373241323701254, 0.10835995034871057], [-0.07921361841395082, 0.10803010003485533, -0.2163285375368841, -0.12956018650951112]], [[0.004790445743118203, 0.015209554256881724], [-0.08949660398663556, 0.06949660398663556], [0.10485055036945583, -0.08485055036945585], [-0.1926207651493171, 0.1726207651493171], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.27295930408933283\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5103389190565745\n","h11: 0.48966108094342553\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.67268023 -0.7140418 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6726802268077045\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51033892 0.48966108]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.48966108094342553\n","e11: -0.48966108094342553\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.        0.2729593 0.        0.       ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.09288924604397315\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.03500814370582615, -0.1110831598051758, 0.02397025286632087, -0.08983194749851131], [-0.11946017329374378, -0.13454881027378554, -0.2373241323701254, 0.10835995034871057], [-0.07921361841395082, 0.13403908892716782, -0.2163285375368841, -0.12956018650951112]], [[0.05375655383746076, -0.03375655383746083], [-0.08949660398663556, 0.06949660398663556], [0.11821630515885062, -0.09821630515885064], [-0.1926207651493171, 0.1726207651493171], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.34113908849241376\n","h01: 0.18906263137468954\n","h02: 0.6439336020331023\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.459837298371378\n","h11: 0.540162701628622\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.77688255 -0.61588489]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6158848854930764\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.4598373 0.5401627]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.459837298371378\n","e11: 0.459837298371378\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.34113909 0.18906263 0.6439336  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.07311100721382763\n","e01: -0.09952378680795698\n","e02: 0.16795167854555176\n","e03: 0.0\n","\n","[[[0.04231924442720891, -0.1210355384859715, 0.04076542072087605, -0.08983194749851131], [-0.1372261480467039, -0.11036453007945199, -0.27813639025669445, 0.10835995034871057], [-0.08067583855822737, 0.13602956466332697, -0.21968757110779513, -0.12956018650951112]], [[0.0077728240003229546, 0.012227175999676973], [-0.10518345166875816, 0.08518345166875815], [0.10952250019541852, -0.08952250019541855], [-0.2222312339382623, 0.20223123393826228], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.09167822869339062\n","h01: 0.44505452808290397\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5166635830256977\n","h11: 0.48333641697430224\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.66036333 -0.72704235]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6603633260921243\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51666358 0.48333642]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4833364169743023\n","e11: -0.48333641697430224\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.09167823 0.44505453 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.09201125696964849\n","e01: 0.09620569730555578\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.03311811873024406, -0.11141496875541591, 0.04076542072087605, -0.08983194749851131], [-0.1197440092224707, -0.1286436125675076, -0.27813639025669445, 0.10835995034871057], [-0.10478278788427528, 0.1612354573573826, -0.21968757110779513, -0.12956018650951112]], [[0.05610646569775319, -0.036106465697753255], [-0.10075230901163675, 0.08075230901163674], [0.1310336062915965, -0.11103360629159653], [-0.2222312339382623, 0.20223123393826228], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.1922182758497048\n","h01: 0.4510522556898108\n","h02: 0.44420408089900076\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.49449058011766084\n","h11: 0.5055094198823391\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.70422718 -0.68218861]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7042271774078666\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.49449058 0.50550942]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5055094198823391\n","e11: -0.5055094198823391\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.19221828 0.45105226 0.44420408 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.09175229416291053\n","e01: 0.12236725620546476\n","e02: -0.21456977589808796\n","e03: 0.0\n","\n","[[[0.023942889313953008, -0.09917824313486943, 0.019308443131067252, -0.08983194749851131], [-0.09607191732843978, -0.1602143646685175, -0.22277738807498776, 0.10835995034871057], [-0.11790336594957149, 0.17873397499476407, -0.2503710490612217, -0.12956018650951112]], [[0.10665740768598711, -0.08665740768598718], [-0.09103549410007997, 0.07103549410007998], [0.15383472270263418, -0.13383472270263422], [-0.19977629921380013, 0.17977629921380012], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.38294540723789433\n","h01: 0.40567353392945454\n","h02: 0.8460276464935808\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4817177450473031\n","h11: 0.5182822549526969\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.73039693 -0.65723529]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6572352913922621\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.48171775 0.51828225]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4817177450473031\n","e11: 0.48171774504730314\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.38294541 0.40567353 0.84602765 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.07807247097336911\n","e01: -0.13857547655963415\n","e02: 0.18283722184138818\n","e03: 0.0\n","\n","[[[0.03175013641128992, -0.11303579079083285, 0.037592165315206066, -0.08983194749851131], [-0.12285077487230539, -0.11268297620856298, -0.2854905551665839, 0.10835995034871057], [-0.11985517772390572, 0.1821983619087549, -0.2549419796072564, -0.12956018650951112]], [[0.058485633181256796, -0.03848563318125686], [-0.10948265390516593, 0.08948265390516594], [0.13429270870364743, -0.11429270870364747], [-0.2405309522254566, 0.22053095222545657], [0.07270331180814317, -0.05270331180814318]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.16613865407312184\n","h01: 0.0\n","h02: 0.29564457997032423\n","h03: 0.33277042437438137\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4923347506395633\n","h11: 0.5076652493604367\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.70859641 -0.67793301]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.708596406369666\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.49233475 0.50766525]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5076652493604368\n","e11: -0.5076652493604367\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.16613865 0.         0.29564458 0.33277042]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.10100777260360819\n","e01: 0.0\n","e02: -0.2340651066936707\n","e03: 0.06366458484961245\n","\n","[[[0.021649359150929096, -0.11303579079083285, 0.014185654645838996, -0.08346548901355007], [-0.13446666872172033, -0.11268297620856298, -0.312408042436356, 0.115681377606416], [-0.09662339002507583, 0.1821983619087549, -0.20110700506771215, -0.14420304102492199]], [[0.10925215811730048, -0.08925215811730053], [-0.10104837178032205, 0.08104837178032206], [0.13429270870364743, -0.11429270870364747], [-0.22552210428418695, 0.20552210428418696], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.033265419621722137\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5515100069918233\n","h11: 0.44848999300817666\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.5950953  -0.80186891]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.801868909865591\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.55151001 0.44848999]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5515100069918233\n","e11: 0.5515100069918233\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.03326542 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.1370973452923625\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.021649359150929096, -0.1267455253200691, 0.014185654645838996, -0.08346548901355007], [-0.13446666872172033, -0.17136063999369414, -0.312408042436356, 0.115681377606416], [-0.09662339002507583, 0.13489977778288983, -0.20110700506771215, -0.14420304102492199]], [[0.05410115741811815, -0.0341011574181182], [-0.10104837178032205, 0.08104837178032206], [0.13245808752283122, -0.11245808752283128], [-0.22552210428418695, 0.20552210428418696], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Epoch 6 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5220362943426822\n","h11: 0.47796370565731783\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.65001816 -0.73822048]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7382204789606793\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.52203629 0.47796371]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5220362943426822\n","e11: 0.5220362943426822\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.021649359150929096, -0.1267455253200691, 0.014185654645838996, -0.08346548901355007], [-0.13446666872172033, -0.17136063999369414, -0.312408042436356, 0.115681377606416], [-0.09662339002507583, 0.13489977778288983, -0.20110700506771215, -0.14420304102492199]], [[0.0018975279838499282, 0.01810247201615002], [-0.10104837178032205, 0.08104837178032206], [0.13245808752283122, -0.11245808752283128], [-0.22552210428418695, 0.20552210428418696], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.3726399068675452\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5187563437345728\n","h11: 0.48124365626542726\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.65632098 -0.73138158]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6563209786260777\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51875634 0.48124366]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4812436562654272\n","e11: -0.48124365626542726\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.37263991 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.11786435555751801\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.021649359150929096, -0.1149590897643173, 0.014185654645838996, -0.08346548901355007], [-0.13446666872172033, -0.17972900923827792, -0.312408042436356, 0.115681377606416], [-0.09662339002507583, 0.16790179733899488, -0.20110700506771215, -0.14420304102492199]], [[0.05002189361039265, -0.03002189361039271], [-0.10104837178032205, 0.08104837178032206], [0.1503911466479658, -0.13039114664796586], [-0.22552210428418695, 0.20552210428418696], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.36772804214972465\n","h01: 0.28820204321689913\n","h02: 0.8135585987797266\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4361809999284916\n","h11: 0.5638190000715084\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.82969798 -0.573022  ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5730220008495456\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.436181 0.563819]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4361809999284916\n","e11: 0.4361809999284916\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.36772804 0.28820204 0.8135586  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.07942713969000387\n","e01: -0.12247190145203446\n","e02: 0.1880132939067386\n","e03: 0.0\n","\n","[[[0.029592073119929483, -0.12720627990952074, 0.03298698403651286, -0.08346548901355007], [-0.15376746366639127, -0.14996833718543354, -0.3580952728556935, 0.115681377606416], [-0.09821193281887591, 0.17035123536803556, -0.20486727094584692, -0.14420304102492199]], [[0.006403793617543493, 0.013596206382456448], [-0.1170879702929834, 0.09708797029298341], [0.13782032110878767, -0.11782032110878772], [-0.2610079845958033, 0.24100798459580333], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.06443499010061798\n","h01: 0.6040537974070561\n","h02: 0.17661575258421147\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5111891154370531\n","h11: 0.4888108845629469\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.67101567 -0.7157796 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6710156683265321\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51118912 0.48881088]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.48881088456294686\n","e11: -0.4888108845629469\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.06443499 0.6040538  0.17661575 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.10469153096992759\n","e01: 0.12495992845261285\n","e02: -0.24539086996527432\n","e03: 0.0\n","\n","[[[0.019122920022936724, -0.11471028706425945, 0.008447897039985428, -0.08346548901355007], [-0.13387607278210503, -0.17371072359142997, -0.31147100756229135, 0.115681377606416], [-0.12564111393299696, 0.20309073662262012, -0.2691596788767488, -0.14420304102492199]], [[0.05528488207383818, -0.035284882073838245], [-0.11393831784219462, 0.09393831784219463], [0.16734712821220268, -0.14734712821220275], [-0.25237481437095943, 0.23237481437095944], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.18485639487658212\n","h01: 0.6238831331719766\n","h02: 0.4271447557569463\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5103526740859758\n","h11: 0.48964732591402416\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.67265327 -0.71406989]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6726532744364013\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51035267 0.48964733]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.48964732591402416\n","e11: -0.48964732591402416\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.18485639 0.62388313 0.42714476 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.101786238782865\n","e01: 0.15408920113871233\n","e02: -0.23735635945129657\n","e03: 0.0\n","\n","[[[0.008944296144650223, -0.09930136695038821, -0.015287738905144233, -0.08346548901355007], [-0.10761522317612586, -0.21346573748521774, -0.2502330668238568, 0.115681377606416], [-0.14019654607894666, 0.22512549238545598, -0.3031016382782842, -0.14420304102492199]], [[0.1042496146652406, -0.08424961466524067], [-0.10488687389925208, 0.08488687389925209], [0.19789539899625483, -0.1778953989962549], [-0.23145978562750066, 0.21145978562750067], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.4131136481584986\n","h01: 0.5766047395275447\n","h02: 0.9187870898702558\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.47996949471130884\n","h11: 0.5200305052886911\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.73403273 -0.65386781]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6538678051106165\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.47996949 0.52003051]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.47996949471130884\n","e11: 0.4799694947113089\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.41311365 0.57660474 0.91878709 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.09108560984031941\n","e01: -0.18036811942962444\n","e02: 0.21258788281301255\n","e03: 0.0\n","\n","[[[0.018052857128682164, -0.11733817889335066, 0.005971049376157025, -0.08346548901355007], [-0.13885758735135542, -0.15159947252085657, -0.32315071062872014, 0.115681377606416], [-0.14247368632495463, 0.2296346953711966, -0.3084163353486095, -0.14420304102492199]], [[0.056252665194109715, -0.03625266519410977], [-0.12471506879575009, 0.1047150687957501], [0.17022013044833667, -0.15022013044833674], [-0.2755587631547307, 0.25555876315473075], [0.08959690985512304, -0.06959690985512304]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.18605611022201904\n","h01: 0.0\n","h02: 0.3437053034549308\n","h03: 0.3812350895911489\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.48199798741156485\n","h11: 0.5180020125884351\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.72981534 -0.65777615]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7298153404349329\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.48199799 0.51800201]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5180020125884351\n","e11: -0.5180020125884351\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.18605611 0.         0.3437053  0.38123509]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.1188452730208387\n","e01: 0.0\n","e02: -0.2751199475492922\n","e03: 0.08246271900154797\n","\n","[[[0.0061683298265982935, -0.11733817889335066, -0.021540945378772196, -0.07521921711339527], [-0.15252479374875189, -0.15159947252085657, -0.35478950459688874, 0.12516459029159402], [-0.11513927353016173, 0.2296346953711966, -0.24513874741227232, -0.16316946639527802]], [[0.10805286645295323, -0.0880528664529533], [-0.11507732484081193, 0.09507732484081194], [0.17022013044833667, -0.15022013044833674], [-0.2577547592620334, 0.23775475926203346], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.02605577774801149\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5509364502109105\n","h11: 0.44906354978908947\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.59613581 -0.80059086]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.8005908649766011\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.55093645 0.44906355]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5509364502109105\n","e11: 0.5509364502109105\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.02605578 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.17654221984307128\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.0061683298265982935, -0.1349924008776578, -0.021540945378772196, -0.07521921711339527], [-0.15252479374875189, -0.2271595426136911, -0.35478950459688874, 0.12516459029159402], [-0.11513927353016173, 0.168727629525337, -0.24513874741227232, -0.16316946639527802]], [[0.05295922143186217, -0.03295922143186224], [-0.11507732484081193, 0.09507732484081194], [0.16878462267833927, -0.14878462267833933], [-0.2577547592620334, 0.23775475926203346], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Epoch 7 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5214664069602086\n","h11: 0.4785335930397913\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.65111042 -0.73702887]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.73702886566353\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.52146641 0.47853359]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5214664069602086\n","e11: 0.5214664069602086\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.0061683298265982935, -0.1349924008776578, -0.021540945378772196, -0.07521921711339527], [-0.15252479374875189, -0.2271595426136911, -0.35478950459688874, 0.12516459029159402], [-0.11513927353016173, 0.168727629525337, -0.24513874741227232, -0.16316946639527802]], [[0.0008125807358413048, 0.01918741926415863], [-0.11507732484081193, 0.09507732484081194], [0.16878462267833927, -0.14878462267833933], [-0.2577547592620334, 0.23775475926203346], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.49872823704900643\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.534944415777448\n","h11: 0.46505558422255194\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.62559243 -0.76559834]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.625592433226755\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.53494442 0.46505558]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.465055584222552\n","e11: -0.46505558422255194\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.49872824 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.14768735093046512\n","e02: 0.0\n","e03: 0.0\n","\n","[[[0.0061683298265982935, -0.12022366578461127, -0.021540945378772196, -0.07521921711339527], [-0.15252479374875189, -0.2376453445297541, -0.35478950459688874, 0.12516459029159402], [-0.11513927353016173, 0.21008008778586723, -0.24513874741227232, -0.16316946639527802]], [[0.04731813915809651, -0.02731813915809657], [-0.11507732484081193, 0.09507732484081194], [0.19197825784325018, -0.17197825784325024], [-0.2577547592620334, 0.23775475926203346], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.3998314333420978\n","h01: 0.41523850386551775\n","h02: 0.889625300274122\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4257825954132949\n","h11: 0.574217404586705\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.8538264 -0.5547472]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5547472007362481\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.4257826 0.5742174]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4257825954132949\n","e11: 0.425782595413295\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.39983143 0.4152385  0.8896253  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.08948019217961359\n","e01: -0.15496634986657776\n","e02: 0.2109793288491693\n","e03: 0.0\n","\n","[[[0.015116349044559652, -0.13572030077126904, -0.0004430124938552653, -0.07521921711339527], [-0.174268480448398, -0.19998852151217572, -0.40605748150723686, 0.12516459029159402], [-0.116928877373754, 0.2131794147831988, -0.2493583339892557, -0.16316946639527802]], [[0.004739879616767022, 0.015260120383232934], [-0.13210145138243357, 0.11210145138243356], [0.17429812505411083, -0.15429812505411086], [-0.29563345619163817, 0.2756334561916382], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.03987280317728037\n","h01: 0.8027879568338457\n","h02: 0.1177473673180448\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5439539105460078\n","h11: 0.4560460894539922\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.60889076 -0.7851614 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6088907589764276\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.54395391 0.45604609]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.45604608945399217\n","e11: -0.4560460894539922\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.0398728  0.80278796 0.11774737 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.11136777883923116\n","e01: 0.14985503487110047\n","e02: -0.2605240414268496\n","e03: 0.0\n","\n","[[[0.0039795711606365365, -0.12073479728415899, -0.026495416636540228, -0.07521921711339527], [-0.15310860246894406, -0.22846097813768482, -0.3565579136361354, 0.12516459029159402], [-0.14610723542963255, 0.25244143391942714, -0.3176156328430903, -0.16316946639527802]], [[0.050344488562166244, -0.03034448856216629], [-0.1302830677859768, 0.11028306778597682], [0.2109089558915944, -0.19090895589159443], [-0.29026363355074847, 0.2702636335507485], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.19006641886613765\n","h01: 0.8296857768158487\n","h02: 0.4392336455790701\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5304984919149832\n","h11: 0.4695015080850168\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.63393816 -0.75608377]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6339381636937172\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.53049849 0.46950151]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4695015080850168\n","e11: -0.4695015080850168\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.19006642 0.82968578 0.43923365 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.11294616344521682\n","e01: 0.1886541155577794\n","e02: -0.26316839722692587\n","e03: 0.0\n","\n","[[[-0.007315045183885146, -0.10186938572838106, -0.05281225635923281, -0.07521921711339527], [-0.12396849230007811, -0.2771337399515919, -0.28866046715158855, 0.12516459029159402], [-0.16225853680229857, 0.27941897244418956, -0.3552487136465407, -0.16316946639527802]], [[0.09729463937066793, -0.07729463937066797], [-0.12135942075657981, 0.10135942075657982], [0.24986282823676736, -0.2298628282367674], [-0.26964154765064313, 0.2496415476506432], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.45846151760595744\n","h01: 0.7788445991945319\n","h02: 1.0261053243823512\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.478332041546573\n","h11: 0.5216679584534271\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.73745014 -0.65072399]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6507239884105088\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.47833204 0.52166796]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.478332041546573\n","e11: 0.47833204154657294\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.45846152 0.7788446  1.02610532 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.10653355815187726\n","e01: -0.22946815264325582\n","e02: 0.2483897431160879\n","e03: 0.0\n","\n","[[[0.0033383106313025802, -0.12481620099270664, -0.027973282047624018, -0.07521921711339527], [-0.160509502746172, -0.19842616359495513, -0.3738581490404067, 0.12516459029159402], [-0.16492187575609552, 0.28515567626027094, -0.3614584572244429, -0.16316946639527802]], [[0.049461435216010624, -0.02946143521601067], [-0.1432891041252796, 0.12328910412527959], [0.21260819551874308, -0.1926081955187431], [-0.318723453116005, 0.29872345311600507], [0.10934496422287779, -0.0893449642228778]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.1980726967122244\n","h01: 0.0\n","h02: 0.373444298172127\n","h03: 0.4440098344310773\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.47097249277427644\n","h11: 0.5290275072257236\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.75295559 -0.63671485]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7529555884242967\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.47097249 0.52902751]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5290275072257236\n","e11: -0.5290275072257236\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.1980727  0.         0.3734443  0.44400983]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.14102720499149313\n","e01: 0.0\n","e02: -0.32664639764815534\n","e03: 0.10511243755651546\n","\n","[[[-0.010764409867846733, -0.12481620099270664, -0.06063792181243955, -0.06470797335774373], [-0.17672763132019373, -0.19842616359495513, -0.4114224847699446, 0.1372525206105933], [-0.13248561860805208, 0.28515567626027094, -0.2863297857653672, -0.18734532703327658]], [[0.10236418593858299, -0.08236418593858302], [-0.1328105136261651, 0.11281051362616511], [0.21260819551874308, -0.1926081955187431], [-0.29896722250103897, 0.27896722250103906], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.009706901918820177\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5470260404014746\n","h11: 0.4529739595985254\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.60325887 -0.79192064]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7919206394813565\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.54702604 0.45297396]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5470260404014746\n","e11: 0.5470260404014746\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.        0.0097069 0.        0.       ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.22166391789501166\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.010764409867846733, -0.14698259278220782, -0.06063792181243955, -0.06470797335774373], [-0.17672763132019373, -0.29329832045402016, -0.4114224847699446, 0.1372525206105933], [-0.13248561860805208, 0.20868162458649192, -0.2863297857653672, -0.18734532703327658]], [[0.04766158189843552, -0.02766158189843556], [-0.1328105136261651, 0.11281051362616511], [0.2120772027066213, -0.19207720270662135], [-0.29896722250103897, 0.27896722250103906], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Epoch 8 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5188218928325866\n","h11: 0.48117810716741327\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.65619463 -0.73151779]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7315177922436739\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51882189 0.48117811]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5188218928325866\n","e11: 0.5188218928325867\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.010764409867846733, -0.14698259278220782, -0.06063792181243955, -0.06470797335774373], [-0.17672763132019373, -0.29329832045402016, -0.4114224847699446, 0.1372525206105933], [-0.13248561860805208, 0.20868162458649192, -0.2863297857653672, -0.18734532703327658]], [[-0.00422060738482314, 0.024220607384823116], [-0.1328105136261651, 0.11281051362616511], [0.2120772027066213, -0.19207720270662135], [-0.29896722250103897, 0.27896722250103906], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.6455677635823238\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5578566406033864\n","h11: 0.4421433593966137\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.58365327 -0.81612111]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5836532660909055\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.55785664 0.44214336]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.44214335939661364\n","e11: -0.4421433593966137\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.64556776 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.17869418652435204\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.010764409867846733, -0.1291131741297726, -0.06063792181243955, -0.06470797335774373], [-0.17672763132019373, -0.30598560769724914, -0.4114224847699446, 0.1372525206105933], [-0.13248561860805208, 0.2587159968133105, -0.2863297857653672, -0.18734532703327658]], [[0.03999372855483823, -0.019993728554838254], [-0.1328105136261651, 0.11281051362616511], [0.24062055267746607, -0.2206205526774661], [-0.29896722250103897, 0.27896722250103906], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.4451808579618345\n","h01: 0.5626886532118807\n","h02: 0.9963846733315993\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.40958814812149413\n","h11: 0.5904118518785059\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.89260314 -0.52693493]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5269349315773982\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.40958815 0.59041185]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.40958814812149413\n","e11: 0.40958814812149413\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.44518086 0.56268865 0.99638467 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.10060346169198098\n","e01: -0.18891889017983765\n","e02: 0.23671509906402463\n","e03: 0.0\n","\n","[[[-0.000704063698648635, -0.14800506314775638, -0.03696641190603708, -0.06470797335774373], [-0.20117427251134512, -0.2600783173835486, -0.4689442538425026, 0.1372525206105933], [-0.1344976878418917, 0.2624943746169072, -0.2910640877466477, -0.18734532703327658]], [[-0.0009650862573111832, 0.02096508625731116], [-0.15104459394533767, 0.13104459394533768], [0.21757349233366288, -0.19757349233366292], [-0.33977795781769193, 0.319777957817692], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.029143111927150855\n","h01: 1.033879001377283\n","h02: 0.09143976049850078\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5838870905562167\n","h11: 0.4161129094437833\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.53804765 -0.87679864]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5380476529347976\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.58388709 0.41611291]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4161129094437833\n","e11: -0.4161129094437833\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.02914311 1.033879   0.09143976 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.11738095269582297\n","e01: 0.17274801963673464\n","e02: -0.2744497309958981\n","e03: 0.0\n","\n","[[[-0.012442158968230933, -0.13073026118408293, -0.06441138500562689, -0.06470797335774373], [-0.17887189149913876, -0.2929004411145282, -0.416798804953282, 0.1372525206105933], [-0.1652514974481973, 0.3077543557617317, -0.362969917267573, -0.18734532703327658]], [[0.04064620468706715, -0.020646204687067175], [-0.14983191143591243, 0.12983191143591244], [0.26059453226125634, -0.24059453226125638], [-0.3359730313397045, 0.3159730313397046], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.21273767974862495\n","h01: 1.0650416056306762\n","h02: 0.4918825500812114\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5535201018331686\n","h11: 0.44647989816683153\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.59145721 -0.8063609 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.591457209817815\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5535201 0.4464799]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4464798981668314\n","e11: -0.44647989816683153\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.21273768 1.06504161 0.49188255 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.12486427515675916\n","e01: 0.22377084249034102\n","e02: -0.29108081167536937\n","e03: 0.0\n","\n","[[[-0.024928586483906848, -0.10835317693504883, -0.09351946617316383, -0.06470797335774373], [-0.1466569085086949, -0.35063331847703616, -0.34169995554103666, 0.1372525206105933], [-0.18310708879561388, 0.33975358623785046, -0.4045944733371508, -0.18734532703327658]], [[0.0852941945037503, -0.06529419450375033], [-0.14033360167687103, 0.12033360167687103], [0.30814649902379865, -0.2881464990237987], [-0.31401146425267445, 0.29401146425267455], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.5238813818998203\n","h01: 1.0093807088817228\n","h02: 1.1796599996668797\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4746856663478272\n","h11: 0.5253143336521727\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.74510245 -0.64375846]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6437584647922232\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.47468567 0.52531433]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4746856663478272\n","e11: 0.4746856663478273\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.52388138 1.00938071 1.17966    0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.12373498511899564\n","e01: -0.2830517391167674\n","e02: 0.2886197689723189\n","e03: 0.0\n","\n","[[[-0.012555087972007283, -0.13665835084672556, -0.06465748927593193, -0.06470797335774373], [-0.1890980084045104, -0.2535465719599849, -0.44069653629854205, 0.1372525206105933], [-0.18620046342358879, 0.3468298797157696, -0.41180996756145877, -0.18734532703327658]], [[0.03782562786896757, -0.017825627868967603], [-0.1652014999623047, 0.1452014999623047], [0.26023264358438236, -0.2402326435843824], [-0.3700082335532495, 0.3500082335532496], [0.1328343058121557, -0.1128343058121557]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.19824326823705993\n","h01: 0.0\n","h02: 0.37570441937209975\n","h03: 0.5240266775209746\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.46315179975898146\n","h11: 0.5368482002410185\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.76970042 -0.62203991]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7697004173801582\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.4631518 0.5368482]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5368482002410185\n","e11: -0.5368482002410185\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.19824327 0.         0.37570442 0.52402668]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.16663929185893958\n","e01: 0.0\n","e02: -0.3865395445100206\n","e03: 0.13188675200622135\n","\n","[[[-0.02921901715790124, -0.13665835084672556, -0.10331144372693399, -0.05151929815712159], [-0.20826152696828845, -0.2535465719599849, -0.4851485839171944, 0.15241949709130875], [-0.14787342629603267, 0.3468298797157696, -0.322905872324154, -0.2176792799947075]], [[0.09151044789306942, -0.07151044789306946], [-0.1545588457860084, 0.13455884578600838], [0.26023264358438236, -0.2402326435843824], [-0.3498386094169987, 0.3298386094169988], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5406652045737245\n","h11: 0.45933479542627553\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.61495504 -0.77797593]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7779759330056373\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5406652 0.4593348]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5406652045737245\n","e11: 0.5406652045737245\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.02921901715790124, -0.13665835084672556, -0.10331144372693399, -0.05151929815712159], [-0.20826152696828845, -0.2535465719599849, -0.4851485839171944, 0.15241949709130875], [-0.14787342629603267, 0.3468298797157696, -0.322905872324154, -0.2176792799947075]], [[0.037443927435696966, -0.017443927435697004], [-0.1545588457860084, 0.13455884578600838], [0.26023264358438236, -0.2402326435843824], [-0.3498386094169987, 0.3298386094169988], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Epoch 9 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5137185197687979\n","h11: 0.48628148023120216\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.66607979 -0.72096765]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7209676453097013\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51371852 0.48628148]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5137185197687979\n","e11: 0.5137185197687979\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.02921901715790124, -0.13665835084672556, -0.10331144372693399, -0.05151929815712159], [-0.20826152696828845, -0.2535465719599849, -0.4851485839171944, 0.15241949709130875], [-0.14787342629603267, 0.3468298797157696, -0.322905872324154, -0.2176792799947075]], [[-0.013927924541182829, 0.03392792454118279], [-0.1545588457860084, 0.13455884578600838], [0.26023264358438236, -0.2402326435843824], [-0.3498386094169987, 0.3298386094169988], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 1.0144833784490186\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6129804575193966\n","h11: 0.3870195424806034\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.48942222 -0.94928009]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.48942222362034304\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.61298046 0.38701954]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.38701954248060344\n","e11: -0.3870195424806034\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         1.01448338 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.19368984646747914\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.02921901715790124, -0.11728936619997765, -0.10331144372693399, -0.05151929815712159], [-0.20826152696828845, -0.26729855105917594, -0.4851485839171944, 0.15241949709130875], [-0.14787342629603267, 0.40106303672666377, -0.322905872324154, -0.2176792799947075]], [[0.024774029706877518, -0.004774029706877549], [-0.1545588457860084, 0.13455884578600838], [0.299495132882534, -0.279495132882534], [-0.3498386094169987, 0.3298386094169988], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.5064311786342462\n","h01: 0.4520335055284872\n","h02: 1.1401807896566793\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.3474873958112848\n","h11: 0.6525126041887152\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.05702689 -0.42692482]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.42692482320754044\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.3474874 0.6525126]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.3474873958112848\n","e11: 0.34748739581128485\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.50643118 0.45203351 1.14018079 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.10046475372733035\n","e01: -0.2011918196507872\n","e02: 0.23617926676488255\n","e03: 0.0\n","\n","[[[-0.019172541785168203, -0.13740854816505638, -0.07969351705044574, -0.05151929815712159], [-0.23267446212402973, -0.21840893888403465, -0.5425401457410609, 0.15241949709130875], [-0.14988272137057929, 0.4050868731196795, -0.3276294576594517, -0.2176792799947075]], [[-0.009974709874250962, 0.029974709874250938], [-0.1721566909281338, 0.15215669092813378], [0.28378753831698, -0.26378753831698004], [-0.38945845475218405, 0.36945845475218414], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0302162062595705\n","h01: 1.3388960432881696\n","h02: 0.09274358078980649\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6486276855914578\n","h11: 0.35137231440854216\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.4328964  -1.04590889]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.43289640086502074\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.64862769 0.35137231]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.3513723144085422\n","e11: -0.35137231440854216\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.03021621 1.33889604 0.09274358 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.11395474357649804\n","e01: 0.1924027219893094\n","e02: -0.26666239093632804\n","e03: 0.0\n","\n","[[[-0.030568016142818007, -0.11816827596612543, -0.10635975614407854, -0.05151929815712159], [-0.2110230608444951, -0.25496545606200344, -0.4918742914631586, 0.15241949709130875], [-0.17973886418762178, 0.4554963862808786, -0.3974950040847696, -0.2176792799947075]], [[0.025162521566603265, -0.005162521566603281], [-0.17109497709552668, 0.15109497709552666], [0.3308326384652404, -0.31083263846524045], [-0.38619970208931903, 0.3661997020893191], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.2568449050476802\n","h01: 1.1910024330554996\n","h02: 0.5942580599896501\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5657858221341046\n","h11: 0.4342141778658954\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.56953968 -0.83421737]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5695396785161081\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.56578582 0.43421418]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.43421417786589545\n","e11: -0.4342141778658954\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.25684491 1.19100243 0.59425806 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.13989944607571875\n","e01: 0.27862016068746087\n","e02: -0.32670248871221697\n","e03: 0.0\n","\n","[[[-0.04455796075038988, -0.09030625989737934, -0.13903000501530025, -0.05151929815712159], [-0.17492900375695966, -0.32684945751936834, -0.4075850493754066, 0.15241949709130875], [-0.19974448497644956, 0.49533906925918547, -0.4442134599706167, -0.2176792799947075]], [[0.06858393935319282, -0.04858393935319282], [-0.15994240716709443, 0.1399424071670944], [0.3825476526957879, -0.3625476526957879], [-0.36039617459346024, 0.34039617459346033], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.6053846433800942\n","h01: 0.9069526120792577\n","h02: 1.3700400793349987\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.41369157754759295\n","h11: 0.5863084224524071\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.88263456 -0.53390931]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5339093096837882\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.41369158 0.58630842]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.41369157754759295\n","e11: 0.4136915775475929\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.60538464 0.90695261 1.37004008 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.12405982192447759\n","e01: -0.3082396523107465\n","e02: 0.28991189246842075\n","e03: 0.0\n","\n","[[[-0.03215197855794212, -0.12113022512845399, -0.11003881576845817, -0.05151929815712159], [-0.21748152267705548, -0.22112325677678227, -0.507024828492075, 0.15241949709130875], [-0.2028459805245615, 0.5030450605669541, -0.4514612572823272, -0.2176792799947075]], [[0.02721478159843352, -0.007214781598433528], [-0.18498665998139424, 0.16498665998139422], [0.34502778701059006, -0.3250277870105901], [-0.41707357876581275, 0.39707357876581284], [0.16096658368269728, -0.1409665836826973]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.1842900255699355\n","h01: 0.0\n","h02: 0.3452435232150082\n","h03: 0.6244254674857106\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4693855183446356\n","h11: 0.5306144816553644\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.75633085 -0.63371954]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7563308474586071\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.46938552 0.53061448]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5306144816553644\n","e11: -0.5306144816553644\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.18429003 0.         0.34524352 0.62442547]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.185700911765262\n","e01: 0.0\n","e02: -0.4319982719848318\n","e03: 0.16021011109615124\n","\n","[[[-0.05072206973446832, -0.12113022512845399, -0.15323864296694134, -0.03549828704750647], [-0.23883712753006062, -0.22112325677678227, -0.5567046297703306, 0.17084365986736616], [-0.16013477081855124, 0.5030450605669541, -0.3521016547258159, -0.2545276055468223]], [[0.08027622976396996, -0.06027622976396997], [-0.17520796434218971, 0.1552079643421897], [0.34502778701059006, -0.3250277870105901], [-0.3987544574542524, 0.3787544574542525], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.6679676948229096\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6429354922578273\n","h11: 0.35706450774217274\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.44171088 -1.02983882]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 1.0298388195700185\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.64293549 0.35706451]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.6429354922578273\n","e11: 0.6429354922578272\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.66796769 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.43080251032340844\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.05072206973446832, -0.16421047616079484, -0.15323864296694134, -0.03549828704750647], [-0.23883712753006062, -0.4055067311952011, -0.5567046297703306, 0.17084365986736616], [-0.16013477081855124, 0.35441819450537815, -0.3521016547258159, -0.2545276055468223]], [[0.01598268053818723, 0.004017319461812746], [-0.17520796434218971, 0.1552079643421897], [0.3020817731422607, -0.28208177314226074], [-0.3987544574542524, 0.3787544574542525], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Epoch 10 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5029913045804558\n","h11: 0.4970086954195441\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.6871824  -0.69914776]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6991477572245862\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5029913 0.4970087]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5029913045804558\n","e11: 0.5029913045804559\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.05072206973446832, -0.16421047616079484, -0.15323864296694134, -0.03549828704750647], [-0.23883712753006062, -0.4055067311952011, -0.5567046297703306, 0.17084365986736616], [-0.16013477081855124, 0.35441819450537815, -0.3521016547258159, -0.2545276055468223]], [[-0.034316449919858355, 0.054316449919858345], [-0.17520796434218971, 0.1552079643421897], [0.3020817731422607, -0.28208177314226074], [-0.3987544574542524, 0.3787544574542525], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 1.1160702476028566\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6372237632119269\n","h11: 0.36277623678807314\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.45063441 -1.01396906]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.45063440846533487\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.63722376 0.36277624]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.36277623678807314\n","e11: -0.36277623678807314\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         1.11607025 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.21192065298987406\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.05072206973446832, -0.14301841086180744, -0.15323864296694134, -0.03549828704750647], [-0.23883712753006062, -0.42055309755748216, -0.5567046297703306, 0.17084365986736616], [-0.16013477081855124, 0.4137559773425429, -0.3521016547258159, -0.2545276055468223]], [[0.001961173758948963, 0.018038826241051027], [-0.17520796434218971, 0.1552079643421897], [0.3425701495839104, -0.3225701495839105], [-0.3987544574542524, 0.3787544574542525], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.5616791043272893\n","h01: 0.7961744207343657\n","h02: 1.2699739383201254\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.3408488511861085\n","h11: 0.6591511488138914\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.07631615 -0.41680241]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.41680240990796125\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.34084885 0.65915115]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.3408488511861085\n","e11: 0.34084885118610864\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.5616791  0.79617442 1.26997394 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.11262188970566189\n","e01: -0.22671230684893634\n","e02: 0.26501302043352176\n","e03: 0.0\n","\n","[[[-0.03945988076390213, -0.16568964154670107, -0.12673734092358915, -0.03549828704750647], [-0.2662042467285365, -0.36546200699319065, -0.6211027937356765, 0.17084365986736616], [-0.16238720861266448, 0.4182902234795216, -0.3574019151344863, -0.2545276055468223]], [[-0.03212371135966189, 0.052123711359661894], [-0.1943527320867096, 0.1743527320867096], [0.315432635918803, -0.2954326359188031], [-0.44204137324552367, 0.4220413732455238], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.040873701455136247\n","h01: 1.6246085572567077\n","h02: 0.11696494952184178\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6882674251416536\n","h11: 0.3117325748583464\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.37357782 -1.16560959]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.37357781723901046\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.68826743 0.31173257]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.3117325748583464\n","e11: -0.3117325748583464\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.0408737  1.62460856 0.11696495 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.11493750371112174\n","e01: 0.19042660408148065\n","e02: -0.269362739454326\n","e03: 0.0\n","\n","[[[-0.050953631135014305, -0.146646981138553, -0.15367361486902176, -0.03549828704750647], [-0.24436612102342337, -0.401643061768672, -0.5699238732393546, 0.17084365986736616], [-0.19250083458497838, 0.46818199374886954, -0.42797495287151976, -0.2545276055468223]], [[-0.0009504538738272506, 0.020950453873827254], [-0.19307856566684953, 0.1730785656668495], [0.36607697678785667, -0.34607697678785676], [-0.43839519475726163, 0.4183951947572618], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.30423476764889895\n","h01: 1.559092369285504\n","h02: 0.7047257954822397\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5922350919937353\n","h11: 0.40776490800626464\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.52385161 -0.89706448]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5238516080730837\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.59223509 0.40776491]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.40776490800626475\n","e11: -0.40776490800626464\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.30423477 1.55909237 0.7047258  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.1493060289741236\n","e01: 0.2903913913660985\n","e02: -0.3493690543610413\n","e03: 0.0\n","\n","[[[-0.06588423403242666, -0.11760784200194316, -0.1886105203051259, -0.03549828704750647], [-0.20584516554809948, -0.4765640407411254, -0.4797866572142059, 0.17084365986736616], [-0.21385159672827805, 0.5097079627142216, -0.47793472764514866, -0.2545276055468223]], [[0.03982603692679923, -0.019826036926799212], [-0.18067293946258348, 0.16067293946258346], [0.42965129244135397, -0.409651292441354], [-0.4096589498408159, 0.38965894984081606], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.693627582979624\n","h01: 1.3895798270615618\n","h02: 1.5765413958508876\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.432662923856763\n","h11: 0.5673370761432369\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.83779632 -0.56680166]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5668016613414438\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.43266292 0.56733708]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.432662923856763\n","e11: 0.4326629238567631\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.69362758 1.38957983 1.5765414  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.14768770602221937\n","e01: -0.3631351103758915\n","e02: 0.3458352195673017\n","e03: 0.0\n","\n","[[[-0.05111546343020472, -0.1539213530395323, -0.15402699834839573, -0.03549828704750647], [-0.25650204871372073, -0.3520086978821946, -0.5984081375257904, 0.17084365986736616], [-0.21754378937883354, 0.5187863404736188, -0.4865806081343312, -0.2545276055468223]], [[-0.0034402554588770784, 0.023440255458877096], [-0.21068363327454984, 0.19068363327454982], [0.3695293253504709, -0.349529325350471], [-0.47787005083182266, 0.4578700508318228], [0.19409950325893116, -0.1740995032589312]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.15425789612033353\n","h01: 0.0\n","h02: 0.27693904220590704\n","h03: 0.7463854145576558\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.48172834482428023\n","h11: 0.5182716551757198\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.73037492 -0.65725574]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7303749237633146\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.48172834 0.51827166]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.5182716551757198\n","e11: -0.5182716551757198\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.1542579  0.         0.27693904 0.74638541]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.2080172775677562\n","e01: 0.0\n","e02: -0.48496757130351387\n","e03: 0.1908271085420682\n","\n","[[[-0.07191719118698034, -0.1539213530395323, -0.20252375547874713, -0.01641557619329965], [-0.2804240356340127, -0.3520086978821946, -0.6541794082256944, 0.192788777349704], [-0.16969981553824962, 0.5187863404736188, -0.375038066734523, -0.298417840511498]], [[0.04838691005869491, -0.02838691005869489], [-0.20268888375992888, 0.18268888375992887], [0.3695293253504709, -0.349529325350471], [-0.4635170852531393, 0.44351708525313943], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.12929429465865994\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.542334400559278\n","h11: 0.457665599440722\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.61187249 -0.78161649]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7816164937697971\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.5423344 0.4576656]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.542334400559278\n","e11: 0.5423344005592781\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.12929429 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.38997024229485855\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.07191719118698034, -0.19291837726901817, -0.20252375547874713, -0.01641557619329965], [-0.2804240356340127, -0.5189159615843941, -0.6541794082256944, 0.192788777349704], [-0.16969981553824962, 0.3842466068818926, -0.375038066734523, -0.298417840511498]], [[-0.00584652999723289, 0.02584652999723292], [-0.20268888375992888, 0.18268888375992887], [0.362517250971527, -0.3425172509715271], [-0.4635170852531393, 0.44351708525313943], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Epoch 11 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4920773981451024\n","h11: 0.5079226018548977\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.70911926 -0.6774262 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6774262015647496\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.4920774 0.5079226]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4920773981451024\n","e11: 0.4920773981451023\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.07191719118698034, -0.19291837726901817, -0.20252375547874713, -0.01641557619329965], [-0.2804240356340127, -0.5189159615843941, -0.6541794082256944, 0.192788777349704], [-0.16969981553824962, 0.3842466068818926, -0.375038066734523, -0.298417840511498]], [[-0.05505426981174313, 0.07505426981174315], [-0.20268888375992888, 0.18268888375992887], [0.362517250971527, -0.3425172509715271], [-0.4635170852531393, 0.44351708525313943], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 1.251402454725201\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6796520803841242\n","h11: 0.3203479196158759\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.38617426 -1.13834763]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.38617425824165086\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.67965208 0.32034792]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.32034791961587583\n","e11: -0.3203479196158759\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         1.25140245 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.22585633595487253\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.07191719118698034, -0.1703327436735309, -0.20252375547874713, -0.01641557619329965], [-0.2804240356340127, -0.53495176143719, -0.6541794082256944, 0.192788777349704], [-0.16969981553824962, 0.4474863809492569, -0.375038066734523, -0.298417840511498]], [[-0.02301947785015554, 0.043019477850155564], [-0.20268888375992888, 0.18268888375992887], [0.40260566826886884, -0.38260566826886894], [-0.4635170852531393, 0.44351708525313943], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.6434531785113204\n","h01: 1.0401027604289896\n","h02: 1.4621398198565951\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.30501659022304173\n","h11: 0.6949834097769583\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.18738911 -0.3638673 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.36386730452677807\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.30501659 0.69498341]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.30501659022304173\n","e11: 0.30501659022304173\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.64345318 1.04010276 1.46213982 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.11754661259667509\n","e01: -0.2395024844752181\n","e02: 0.27666046990361015\n","e03: 0.0\n","\n","[[[-0.06016252992731283, -0.1942829921210527, -0.1748577084883861, -0.01641557619329965], [-0.30898786249500476, -0.47675265770971204, -0.7214079024122717, 0.192788777349704], [-0.17205074779018312, 0.4522764306387613, -0.3805712761325952, -0.298417840511498]], [[-0.05352113687245971, 0.07352113687245973], [-0.222315273207699, 0.202315273207699], [0.3708808085221065, -0.35088080852210657], [-0.5081147754813384, 0.4881147754813385], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.07614144960291641\n","h01: 1.8965113058009546\n","h02: 0.19872056262753068\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.7333103743200754\n","h11: 0.2666896256799245\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.31018624 -1.32166975]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.31018623653928895\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.73331037 0.26668963]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.2666896256799246\n","e11: -0.2666896256799245\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.07614145 1.89651131 0.19872056 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.11324456147578432\n","e01: 0.1924863354796582\n","e02: -0.2656840860375156\n","e03: 0.0\n","\n","[[[-0.07148698607489126, -0.17503435857308688, -0.20142611709213767, -0.01641557619329965], [-0.28747139581460573, -0.5133250614508471, -0.6709279260651437, 0.192788777349704], [-0.20172082289683863, 0.5027078505344318, -0.45018050667442433, -0.298417840511498]], [[-0.02685217430446725, 0.04685217430446728], [-0.22028465973836614, 0.20028465973836612], [0.4214587975462866, -0.4014587975462867], [-0.5028151042351344, 0.4828151042351345], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.3817284383843123\n","h01: 1.868216526234336\n","h02: 0.8858098076115065\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6058879306871396\n","h11: 0.3941120693128603\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.50106024 -0.93111997]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5010602428745179\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.60588793 0.39411207]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.39411206931286036\n","e11: -0.3941120693128603\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.38172844 1.86821653 0.88580981 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.16575144478847642\n","e01: 0.3243217562758966\n","e02: -0.3884487610374836\n","e03: 0.0\n","\n","[[[-0.0880621305537389, -0.14260218294549723, -0.24027099319588605, -0.01641557619329965], [-0.2447075230591788, -0.5970000745700285, -0.570708145717473, 0.192788777349704], [-0.22542327950159075, 0.549085861681885, -0.5057286795027844, -0.298417840511498]], [[0.012559032626818789, 0.0074409673731812495], [-0.20524028126164534, 0.18524028126164532], [0.4950874656541564, -0.4750874656541565], [-0.4679042706055947, 0.4479042706055948], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.8076404934146422\n","h01: 1.7678366074092293\n","h02: 1.8436901164907424\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.42956987949702274\n","h11: 0.5704301205029774\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.84497085 -0.56136461]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5613646053453489\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.42956988 0.57043012]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.42956987949702274\n","e11: 0.42956987949702263\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.80764049 1.76783661 1.84369012 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.1677386881890596\n","e01: -0.41675792833314423\n","e02: 0.3934037646904348\n","e03: 0.0\n","\n","[[[-0.07128826173483294, -0.18427797577881166, -0.20093061672684256, -0.01641557619329965], [-0.30224189310802624, -0.45405210515176, -0.7056456370062921, 0.192788777349704], [-0.22961674670631724, 0.5595048098902136, -0.5155637736200454, -0.298417840511498]], [[-0.030397955322883488, 0.05039795532288351], [-0.23993408420494972, 0.2199340842049497], [0.41914652981263556, -0.3991465298126357], [-0.5471036447226727, 0.5271036447226728], [0.23278254367911239, -0.21278254367911242]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.10925207861546654\n","h01: 0.0\n","h02: 0.17337358004202574\n","h03: 0.8916525509353053\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5199924899470955\n","h11: 0.4800075100529046\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.65394091 -0.73395353]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6539409099203884\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.51999249 0.48000751]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.48000751005290454\n","e11: -0.4800075100529046\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.10925208 0.         0.17337358 0.89165255]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.2207401744710256\n","e01: 0.0\n","e02: -0.51562756628734\n","e03: 0.2138745881493264\n","\n","[[[-0.0933622791819355, -0.18427797577881166, -0.25249337335557653, 0.004971882621632992], [-0.32762701317219417, -0.45405210515176, -0.7649428071293363, 0.21738435498687655], [-0.17884650657798135, 0.5595048098902136, -0.3969694333739572, -0.3476089957858431]], [[0.01760279568240697, 0.002397204317593049], [-0.2346899023825183, 0.21468990238251828], [0.41914652981263556, -0.3991465298126357], [-0.5387815826761796, 0.5187815826761797], [0.27558253575979, -0.25558253575979006]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5038013245994613\n","h11: 0.4961986754005388\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.68557329 -0.70077888]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7007788772150233\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.50380132 0.49619868]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5038013245994613\n","e11: 0.5038013245994613\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.0933622791819355, -0.18427797577881166, -0.25249337335557653, 0.004971882621632992], [-0.32762701317219417, -0.45405210515176, -0.7649428071293363, 0.21738435498687655], [-0.17884650657798135, 0.5595048098902136, -0.3969694333739572, -0.3476089957858431]], [[-0.03277733677753916, 0.05277733677753918], [-0.2346899023825183, 0.21468990238251828], [0.41914652981263556, -0.3991465298126357], [-0.5387815826761796, 0.5187815826761797], [0.27558253575979, -0.25558253575979006]]]\n","[●] Epoch 12 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.47862436844749223\n","h11: 0.5213756315525078\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.73683919 -0.65128452]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6512845151447203\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.47862437 0.52137563]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.47862436844749223\n","e11: 0.47862436844749223\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.0933622791819355, -0.18427797577881166, -0.25249337335557653, 0.004971882621632992], [-0.32762701317219417, -0.45405210515176, -0.7649428071293363, 0.21738435498687655], [-0.17884650657798135, 0.5595048098902136, -0.3969694333739572, -0.3476089957858431]], [[-0.08063977362228839, 0.1006397736222884], [-0.2346899023825183, 0.21468990238251828], [0.41914652981263556, -0.3991465298126357], [-0.5387815826761796, 0.5187815826761797], [0.27558253575979, -0.25558253575979006]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 1.7047124865715357\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.7709485253065333\n","h11: 0.22905147469346654\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.26013367 -1.47380852]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.2601336711929446\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.77094853 0.22905147]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.22905147469346665\n","e11: -0.22905147469346654\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         1.70471249 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.18743123203859718\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.0933622791819355, -0.16553485257495196, -0.25249337335557653, 0.004971882621632992], [-0.32762701317219417, -0.4673597226265004, -0.7649428071293363, 0.21738435498687655], [-0.17884650657798135, 0.6119855548610208, -0.3969694333739572, -0.3476089957858431]], [[-0.05773462615294172, 0.07773462615294174], [-0.2346899023825183, 0.21468990238251828], [0.45819322071039326, -0.43819322071039335], [-0.5387815826761796, 0.5187815826761797], [0.27558253575979, -0.25558253575979006]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.7385406641420926\n","h01: 0.8477521624352399\n","h02: 1.685711534643502\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.1838936022530974\n","h11: 0.8161063977469025\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.69339794 -0.20321054]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.20321054312227457\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.1838936 0.8161064]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.1838936022530974\n","e11: 0.18389360225309748\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.73854066 0.84775216 1.68571153 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.08263807107803622\n","e01: -0.16483973172370356\n","e02: 0.19447910008683347\n","e03: 0.0\n","\n","[[[-0.08509847207413188, -0.1820188257473223, -0.2330454633468932, 0.004971882621632992], [-0.347708064444157, -0.4273036678176404, -0.8122012284504369, 0.21738435498687655], [-0.18049926799954208, 0.6152823494954949, -0.40085901537569385, -0.3476089957858431]], [[-0.07612398637825146, 0.0961239863782515], [-0.24827119269646675, 0.22827119269646673], [0.44260360081358635, -0.42260360081358644], [-0.5697807393226987, 0.5497807393226988], [0.27558253575979, -0.25558253575979006]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.10263876821096601\n","h01: 2.241897898784391\n","h02: 0.25988625042461866\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.8065252007132527\n","h11: 0.19347479928674724\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.21502013 -1.64260801]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.21502013489543834\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.8065252 0.1934748]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.19347479928674727\n","e11: -0.19347479928674724\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.10263877 2.2418979  0.25988625 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.09219894236552556\n","e01: 0.1673957896762655\n","e02: -0.21660693237009224\n","e03: 0.0\n","\n","[[[-0.09431836631068444, -0.16527924677969577, -0.2547061565839024, 0.004971882621632992], [-0.33019026539470714, -0.45910886785613086, -0.7710459113001193, 0.21738435498687655], [-0.20465539089930979, 0.6591400463906765, -0.45761003165665803, -0.3476089957858431]], [[-0.056776506449576734, 0.07677650644957677], [-0.24628539118860118, 0.22628539118860116], [0.48597867541245543, -0.46597867541245547], [-0.5647525953088698, 0.5447525953088699], [0.27558253575979, -0.25558253575979006]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.46491530942164694\n","h01: 1.9617918986277894\n","h02: 1.0802099493013846\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5782967477965216\n","h11: 0.4217032522034784\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.54766814 -0.86345341]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5476681375645029\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.57829675 0.42170325]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.4217032522034784\n","e11: -0.4217032522034784\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.46491531 1.9617919  1.08020995 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.19928463582480846\n","e01: 0.40144351080187257\n","e02: -0.467881947220141\n","e03: 0.0\n","\n","[[[-0.11424682989316529, -0.1251348956995085, -0.3014943513059165, 0.004971882621632992], [-0.27877482935190656, -0.562681293643014, -0.6503323689173229, 0.21738435498687655], [-0.2331530938222574, 0.7165464684353442, -0.5245171501091382, -0.3476089957858431]], [[-0.014606181229228896, 0.034606181229228934], [-0.2266797613903717, 0.20667976139037167], [0.568708077792233, -0.548708077792233], [-0.519199790440575, 0.49919979044057505], [0.27558253575979, -0.25558253575979006]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.9002391082394386\n","h01: 1.6257253243871936\n","h02: 2.0602749616077856\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.327192413079286\n","h11: 0.6728075869207141\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.11720686 -0.39629589]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.3962958937509598\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.32719241 0.67280759]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.327192413079286\n","e11: 0.3271924130792859\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.90023911 1.62572532 2.06027496 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.14179194798951922\n","e01: -0.36561008835946024\n","e02: 0.33321261634743693\n","e03: 0.0\n","\n","[[[-0.10006763509421336, -0.16169590453545452, -0.2681730896711728, 0.004971882621632992], [-0.32740946751231165, -0.4372770333357191, -0.7646242963244938, 0.21738435498687655], [-0.23669789252199538, 0.7256867206443307, -0.5328474655178241, -0.3476089957858431]], [[-0.0473254225371575, 0.06732542253715754], [-0.25613490200769234, 0.23613490200769233], [0.5155155786031979, -0.4955155786031979], [-0.5866104240701034, 0.5666104240701035], [0.27558253575979, -0.25558253575979006]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.06781663006721761\n","h01: 0.0\n","h02: 0.0780581402466547\n","h03: 1.0544645811639801\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5798217141838052\n","h11: 0.42017828581619465\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.54503461 -0.86707617]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5450346120337253\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.57982171 0.42017829]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.42017828581619476\n","e11: -0.42017828581619465\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.06781663 0.         0.07805814 1.05446458]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.20684108241025845\n","e01: 0.0\n","e02: -0.4845583591390503\n","e03: 0.22318402923653363\n","\n","[[[-0.1207517433352392, -0.16169590453545452, -0.3166289255850778, 0.027290285545286355], [-0.35119619198949137, -0.4372770333357191, -0.8203485076254846, 0.24305051834907793], [-0.18912444356763594, 0.7256867206443307, -0.42139904291584257, -0.39894132251024583]], [[-0.005307593955538016, 0.02530759395553807], [-0.2532853944705449, 0.2332853944705449], [0.5155155786031979, -0.4955155786031979], [-0.5833305905138195, 0.5633305905138196], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.47037757901060884\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6094381681824921\n","h11: 0.3905618318175079\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.49521778 -0.94016898]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.9401689821152112\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.60943817 0.39056183]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.6094381681824921\n","e11: 0.6094381681824921\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.47037758 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.616160976423291\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1207517433352392, -0.22331200217778363, -0.3166289255850778, 0.027290285545286355], [-0.35119619198949137, -0.7009939312448876, -0.8203485076254846, 0.24305051834907793], [-0.18912444356763594, 0.5131111837782952, -0.42139904291584257, -0.39894132251024583]], [[-0.06625141077378723, 0.08625141077378728], [-0.2532853944705449, 0.2332853944705449], [0.48684897359256374, -0.46684897359256383], [-0.5833305905138195, 0.5633305905138196], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Epoch 13 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4619480143126419\n","h11: 0.538051985687358\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.77230292 -0.6198001 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6198000958168363\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.46194801 0.53805199]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4619480143126419\n","e11: 0.461948014312642\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1207517433352392, -0.22331200217778363, -0.3166289255850778, 0.027290285545286355], [-0.35119619198949137, -0.7009939312448876, -0.8203485076254846, 0.24305051834907793], [-0.18912444356763594, 0.5131111837782952, -0.42139904291584257, -0.39894132251024583]], [[-0.11244621220505141, 0.13244621220505148], [-0.2532853944705449, 0.2332853944705449], [0.48684897359256374, -0.46684897359256383], [-0.5833305905138195, 0.5633305905138196], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 1.711105003585313\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.8001104641207193\n","h11: 0.1998895358792808\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.22300548 -1.60999039]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.22300548069549722\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.80011046 0.19988954]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.1998895358792807\n","e11: -0.1998895358792808\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.       1.711105 0.       0.      ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.19063424003185797\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1207517433352392, -0.20424857817459782, -0.3166289255850778, 0.027290285545286355], [-0.35119619198949137, -0.7145289622871496, -0.8203485076254846, 0.24305051834907793], [-0.18912444356763594, 0.5664887709872155, -0.42139904291584257, -0.39894132251024583]], [[-0.09245725861712334, 0.1124572586171234], [-0.2532853944705449, 0.2332853944705449], [0.521052172093302, -0.5010521720933022], [-0.5833305905138195, 0.5633305905138196], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.7704798919127521\n","h01: 1.4187590459857327\n","h02: 1.7610977565280184\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.24065896031704867\n","h11: 0.7593410396829512\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.42437445 -0.27530427]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.2753042748584228\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.24065896 0.75934104]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.24065896031704867\n","e11: 0.2406589603170488\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.77047989 1.41875905 1.76109776 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.11709762018720882\n","e01: -0.2459785688074871\n","e02: 0.27595428766203084\n","e03: 0.0\n","\n","[[[-0.10904198131651832, -0.22884643505534652, -0.28903349681887475, 0.027290285545286355], [-0.3796509136949831, -0.6547561700669302, -0.8874053995273581, 0.24305051834907793], [-0.19146639597138013, 0.5714083423633652, -0.4269181286690832, -0.39894132251024583]], [[-0.1165231546488282, 0.13652315464882828], [-0.2718276834438364, 0.2518276834438364], [0.4869084643985686, -0.46690846439856876], [-0.6257129860240915, 0.6057129860240916], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.11065279725893362\n","h01: 2.512280145063838\n","h02: 0.2785112651701074\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.8509788567707345\n","h11: 0.14902114322926552\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.161368   -1.90366708]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.16136799587518277\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.85097886 0.14902114]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.14902114322926552\n","e11: -0.14902114322926552\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.1106528  2.51228015 0.27851127 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.07803572143174148\n","e01: 0.14213888916077638\n","e02: -0.18350850615682981\n","e03: 0.0\n","\n","[[[-0.11684555345969247, -0.21463254613926888, -0.3073843474345577, 0.027290285545286355], [-0.3648241266229522, -0.6817625590074777, -0.8525387833575604, 0.24305051834907793], [-0.2119117549864964, 0.6086487313234886, -0.4749973572821726, -0.39894132251024583]], [[-0.10162104032590165, 0.12162104032590172], [-0.2701787228089322, 0.25017872280893216], [0.5243467503315284, -0.5043467503315285], [-0.6215625793103037, 0.6015625793103038], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.5213668835968345\n","h01: 2.4146825418926126\n","h02: 1.2129194927144415\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6238393732639943\n","h11: 0.3761606267360057\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.47186236 -0.97773903]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.4718623583905796\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.62383937 0.37616063]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.3761606267360057\n","e11: -0.3761606267360057\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.52136688 2.41468254 1.21291949 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.19573798287036287\n","e01: 0.3869539919286712\n","e02: -0.46009152624330407\n","e03: 0.0\n","\n","[[[-0.13641935174672876, -0.17593714694640175, -0.35339350005888814, 0.027290285545286355], [-0.3143237270423986, -0.781596688925075, -0.733835169586788, 0.24305051834907793], [-0.23990228653695828, 0.6639831521692886, -0.5407904455349651, -0.39894132251024583]], [[-0.06400497765230108, 0.08400497765230115], [-0.2505669534396138, 0.23056695343961384], [0.6151776001642101, -0.5951776001642102], [-0.5759373236543255, 0.5559373236543256], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 1.0016866036429382\n","h01: 2.338943708024283\n","h02: 2.298858743007536\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4010666757306549\n","h11: 0.5989333242693451\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.91362759 -0.512605  ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5126049987996193\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.40106668 0.59893332]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4010666757306549\n","e11: 0.4010666757306549\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[1.0016866  2.33894371 2.29885874 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.19296677661335432\n","e01: -0.48543313664903043\n","e02: 0.4539572021398881\n","e03: 0.0\n","\n","[[[-0.11712267408539333, -0.2244804606113048, -0.30799777984489934, 0.027290285545286355], [-0.3805113314207791, -0.6150931230544575, -0.8895424899207696, 0.24305051834907793], [-0.24472645595229214, 0.6761189805855143, -0.5521393755884624, -0.39894132251024583]], [[-0.10411164522536658, 0.12411164522536665], [-0.2907412650643142, 0.2707412650643142], [0.521370362394367, -0.501370362394367], [-0.6681368870575639, 0.648136887057564], [0.3198888477765273, -0.29988884777652736]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.008160143470982706\n","h01: 0.0\n","h02: 0.0\n","h03: 1.2243634234202914\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6285562475031308\n","h11: 0.3714437524968692\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.46432976 -0.99035783]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.4643297601223195\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.62855625 0.37144375]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.37144375249686923\n","e11: -0.3714437524968692\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.00816014 0.         0.         1.22436342]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.20855917795241413\n","e01: 0.0\n","e02: 0.0\n","e03: 0.2302125529500888\n","\n","[[[-0.13797859188063474, -0.2244804606113048, -0.30799777984489934, 0.05031154084029524], [-0.4044956368853067, -0.6150931230544575, -0.8895424899207696, 0.26952496193833814], [-0.1967578450232369, 0.6761189805855143, -0.5521393755884624, -0.45189020968876625]], [[-0.06696726997567964, 0.08696726997567973], [-0.29043816163313674, 0.2704381616331367], [0.521370362394367, -0.501370362394367], [-0.6681368870575639, 0.648136887057564], [0.36536706221804194, -0.345367062218042]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4615921772202253\n","h11: 0.5384078227797747\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.77307351 -0.61913897]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.6191389710770573\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.46159218 0.53840782]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4615921772202253\n","e11: 0.4615921772202253\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.13797859188063474, -0.2244804606113048, -0.30799777984489934, 0.05031154084029524], [-0.4044956368853067, -0.6150931230544575, -0.8895424899207696, 0.26952496193833814], [-0.1967578450232369, 0.6761189805855143, -0.5521393755884624, -0.45189020968876625]], [[-0.11312648769770217, 0.13312648769770224], [-0.29043816163313674, 0.2704381616331367], [0.521370362394367, -0.501370362394367], [-0.6681368870575639, 0.648136887057564], [0.36536706221804194, -0.345367062218042]]]\n","[●] Epoch 14 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4387459834164413\n","h11: 0.5612540165835587\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.82383466 -0.57758168]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5775816834549623\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.43874598 0.56125402]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4387459834164413\n","e11: 0.43874598341644133\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.13797859188063474, -0.2244804606113048, -0.30799777984489934, 0.05031154084029524], [-0.4044956368853067, -0.6150931230544575, -0.8895424899207696, 0.26952496193833814], [-0.1967578450232369, 0.6761189805855143, -0.5521393755884624, -0.45189020968876625]], [[-0.15700108603934632, 0.1770010860393464], [-0.29043816163313674, 0.2704381616331367], [0.521370362394367, -0.501370362394367], [-0.6681368870575639, 0.648136887057564], [0.36536706221804194, -0.345367062218042]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 2.1053688023968\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.8604754174587729\n","h11: 0.13952458254122724\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.15027023 -1.96951447]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.15027023147972093\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.86047542 0.13952458]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.13952458254122713\n","e11: -0.13952458254122724\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.        2.1053688 0.        0.       ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.14269747267406024\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.13797859188063474, -0.2102107133438988, -0.30799777984489934, 0.05031154084029524], [-0.4044956368853067, -0.6252246436143158, -0.8895424899207696, 0.26952496193833814], [-0.1967578450232369, 0.7160742729342512, -0.5521393755884624, -0.45189020968876625]], [[-0.1430486277852236, 0.16304862778522367], [-0.29043816163313674, 0.2704381616331367], [0.5507454327193406, -0.5307454327193407], [-0.6681368870575639, 0.648136887057564], [0.36536706221804194, -0.345367062218042]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.884297374755308\n","h01: 1.1658703160520387\n","h02: 1.9640183457802634\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.10655852573812757\n","h11: 0.8934414742618724\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-2.23906091 -0.11267445]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.11267444819348588\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.10655853 0.89344147]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.10655852573812757\n","e11: 0.10655852573812763\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.88429737 1.16587032 1.96401835 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.05976615412867557\n","e01: -0.11524207222039762\n","e02: 0.1402601928374692\n","e03: 0.0\n","\n","[[[-0.13200197646776718, -0.22173492056593855, -0.29397176056115243, 0.05031154084029524], [-0.41901881233857485, -0.5972208200647592, -0.9236257167802746, 0.26952496193833814], [-0.1979531681058104, 0.7183791143786591, -0.5549445794452118, -0.45189020968876625]], [[-0.15370448035903636, 0.17370448035903643], [-0.29986110408993893, 0.2798611040899389], [0.5383220905113056, -0.5183220905113057], [-0.6890651770024621, 0.6690651770024622], [0.36536706221804194, -0.345367062218042]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.14549646653830173\n","h01: 2.795137917229191\n","h02: 0.006962303174914197\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9263722396017973\n","h11: 0.07362776039820268\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.07647914 -2.60873315]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.07647913849991697\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.92637224 0.07362776]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.07362776039820274\n","e11: -0.07362776039820268\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.14549647 2.79513792 0.0069623  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.042683647841385036\n","e01: 0.07779834458648796\n","e02: -0.09999609629420078\n","e03: 0.0\n","\n","[[[-0.13627034125190568, -0.21395508610728975, -0.3039713701905725, 0.05031154084029524], [-0.4109089192487117, -0.6120025055361918, -0.9046264584843765, 0.26952496193833814], [-0.2091362838402533, 0.7387622806603189, -0.5811435566742924, -0.45189020968876625]], [[-0.1463417043192161, 0.16634170431921616], [-0.2987898461922322, 0.2787898461922322], [0.5589020649962738, -0.5389020649962739], [-0.6890139151234639, 0.669013915123464], [0.36536706221804194, -0.345367062218042]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.6248097845182082\n","h01: 2.4214414395203407\n","h02: 1.1989296066548807\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.588199650521598\n","h11: 0.411800349478402\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.53068885 -0.88721664]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5306888470113513\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.58819965 0.41180035]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.41180034947840205\n","e11: -0.411800349478402\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.62480978 2.42144144 1.19892961 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.23784751917555036\n","e01: 0.4520761243897642\n","e02: -0.5592363350970809\n","e03: 0.0\n","\n","[[[-0.1600550931694607, -0.16874747366831333, -0.3598950037002806, 0.05031154084029524], [-0.3495442593014197, -0.728638145628751, -0.7603434840293296, 0.26952496193833814], [-0.24314847908235698, 0.8034091664480552, -0.661114352593175, -0.45189020968876625]], [[-0.10516166937137589, 0.12516166937137596], [-0.2730601574300199, 0.25306015743001986], [0.65861710809987, -0.63861710809987], [-0.6396419520214156, 0.6196419520214157], [0.36536706221804194, -0.345367062218042]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 1.099668836004998\n","h01: 2.1296290742262887\n","h02: 2.4133617346686136\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.25249277483785276\n","h11: 0.7475072251621472\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.37637265 -0.29101131]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.29101130799525005\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.25249277 0.74750723]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.25249277483785276\n","e11: 0.2524927748378528\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[1.09966884 2.12962907 2.41336173 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.13284157819757622\n","e01: -0.32754226686287935\n","e02: 0.3179600872404188\n","e03: 0.0\n","\n","[[[-0.1467709353497031, -0.20150170035460127, -0.32809899497623873, 0.05031154084029524], [-0.39510892062318836, -0.6162911480947834, -0.8694037939527932, 0.26952496193833814], [-0.2464695185372964, 0.8115977231196272, -0.6690633547741854, -0.45189020968876625]], [[-0.13041094685516116, 0.15041094685516124], [-0.3008260010105812, 0.28082600101058125], [0.6048455126671937, -0.5848455126671938], [-0.7005775921288128, 0.6805775921288129], [0.36536706221804194, -0.345367062218042]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.2109323579586755\n","h03: 1.3996127293535465\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6041053145002631\n","h11: 0.395894685499737\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.50400673 -0.92660705]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5040067344911638\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.60410531 0.39589469]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.39589468549973694\n","e11: -0.395894685499737\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.         0.21093236 1.39961273]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: -0.546791997298004\n","e03: 0.2813758626675543\n","\n","[[[-0.1467709353497031, -0.20150170035460127, -0.38277819470603913, 0.07844912710705067], [-0.39510892062318836, -0.6162911480947834, -0.9322848736420637, 0.3018831861451069], [-0.2464695185372964, 0.8115977231196272, -0.5433011953956446, -0.5166066581023038]], [[-0.09082147830518747, 0.11082147830518754], [-0.3008260010105812, 0.28082600101058125], [0.6048455126671937, -0.5848455126671938], [-0.692226892177236, 0.6722268921772361], [0.420776986348927, -0.40077698634892706]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.4497593770821852\n","h11: 0.5502406229178147\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.79904256 -0.5973996 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5973996002149771\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.44975938 0.55024062]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.4497593770821852\n","e11: 0.4497593770821853\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1467709353497031, -0.20150170035460127, -0.38277819470603913, 0.07844912710705067], [-0.39510892062318836, -0.6162911480947834, -0.9322848736420637, 0.3018831861451069], [-0.2464695185372964, 0.8115977231196272, -0.5433011953956446, -0.5166066581023038]], [[-0.135797416013406, 0.15579741601340608], [-0.3008260010105812, 0.28082600101058125], [0.6048455126671937, -0.5848455126671938], [-0.692226892177236, 0.6722268921772361], [0.420776986348927, -0.40077698634892706]]]\n","[●] Epoch 15 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.42761347069167255\n","h11: 0.5723865293083275\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.8495356  -0.55794077]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5579407652798948\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.42761347 0.57238653]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.42761347069167255\n","e11: 0.42761347069167255\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1467709353497031, -0.20150170035460127, -0.38277819470603913, 0.07844912710705067], [-0.39510892062318836, -0.6162911480947834, -0.9322848736420637, 0.3018831861451069], [-0.2464695185372964, 0.8115977231196272, -0.5433011953956446, -0.5166066581023038]], [[-0.17855876308257326, 0.19855876308257334], [-0.3008260010105812, 0.28082600101058125], [0.6048455126671937, -0.5848455126671938], [-0.692226892177236, 0.6722268921772361], [0.420776986348927, -0.40077698634892706]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 2.508538639527651\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9313278978247365\n","h11: 0.06867210217526357\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.07114386 -2.67841224]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.07114386411586482\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.9313279 0.0686721]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.06867210217526354\n","e11: -0.06867210217526357\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         2.50853864 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.08169858364875712\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1467709353497031, -0.19333184198972556, -0.38277819470603913, 0.07844912710705067], [-0.39510892062318836, -0.6220917475338451, -0.9322848736420637, 0.3018831861451069], [-0.2464695185372964, 0.8344733265412791, -0.5433011953956446, -0.5166066581023038]], [[-0.17169155286504692, 0.19169155286504697], [-0.3008260010105812, 0.28082600101058125], [0.6220721748436177, -0.6020721748436177], [-0.692226892177236, 0.6722268921772361], [0.420776986348927, -0.40077698634892706]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.8626376454721041\n","h01: 1.151456439209262\n","h02: 1.9913342873233046\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.10223146888534691\n","h11: 0.8977685311146532\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-2.28051573 -0.107843  ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.10784300435726074\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.10223147 0.89776853]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.10223146888534691\n","e11: 0.10223146888534684\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.86263765 1.15145644 1.99133429 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.05946313854672619\n","e01: -0.1251460749962238\n","e02: 0.13949011460072802\n","e03: 0.0\n","\n","[[[-0.14082462149503047, -0.20584644948934794, -0.3688291832459663, 0.07844912710705067], [-0.4095584632900428, -0.5916812513097627, -0.9661809714900406, 0.3018831861451069], [-0.24765878130823094, 0.8369762480412036, -0.5460909976876591, -0.5166066581023038]], [[-0.1819146997535816, 0.20191469975358164], [-0.30964487237182226, 0.2896448723718223], [0.6103006665298323, -0.5903006665298324], [-0.7125845951007177, 0.6925845951007178], [0.420776986348927, -0.40077698634892706]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 3.1112256978671544\n","h02: 0.03615624864344391\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9644530458516588\n","h11: 0.03554695414834105\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.03619413 -3.3369008 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.036194130193945774\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.96445305 0.03554695]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.03554695414834119\n","e11: -0.03554695414834105\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         3.1112257  0.03615625 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.04267772053670913\n","e02: -0.049949484774752057\n","e03: 0.0\n","\n","[[[-0.14082462149503047, -0.20157867743567703, -0.37382413172344153, 0.07844912710705067], [-0.4095584632900428, -0.5997900182117374, -0.9566905693828377, 0.3018831861451069], [-0.24765878130823094, 0.8481578108218214, -0.5591777626986442, -0.5166066581023038]], [[-0.1783600043387475, 0.19836000433874754], [-0.30964487237182226, 0.2896448723718223], [0.6213601262525548, -0.6013601262525547], [-0.7124560706494473, 0.6924560706494474], [0.420776986348927, -0.40077698634892706]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.5616841565225097\n","h01: 2.55874523902581\n","h02: 1.2948133366252188\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6447862358871939\n","h11: 0.3552137641128061\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.43883643 -1.03503552]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.4388364343463483\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.64478624 0.35521376]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.35521376411280614\n","e11: -0.3552137641128061\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.56168416 2.55874524 1.29481334 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.21287596602459274\n","e01: 0.4343270633493007\n","e02: -0.4990441299585629\n","e03: 0.0\n","\n","[[[-0.16211221809748974, -0.15814597110074696, -0.42372854471929783, 0.07844912710705067], [-0.3546364640556979, -0.711846400555857, -0.8279371838535284, 0.3018831861451069], [-0.2781000444497477, 0.9102665808807714, -0.6305410732827187, -0.5166066581023038]], [[-0.14283862792746688, 0.16283862792746692], [-0.2896930780237335, 0.26969307802373355], [0.7122502790285627, -0.6922502790285627], [-0.6664625187368367, 0.6464625187368368], [0.420776986348927, -0.40077698634892706]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 1.1238158647259908\n","h01: 2.0559205375856497\n","h02: 2.573731264218985\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.19373847707709216\n","h11: 0.8062615229229079\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.64124609 -0.21534712]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.21534711897687933\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.19373848 0.80626152]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.19373847707709216\n","e11: 0.19373847707709213\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[1.12381586 2.05592054 2.57373126 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.10837462197064487\n","e01: -0.2721057991719135\n","e02: 0.25436409727653364\n","e03: 0.0\n","\n","[[[-0.15127475590042525, -0.18535655101793833, -0.39829213499164445, 0.07844912710705067], [-0.3918089593916291, -0.6185141114398907, -0.9151840692193794, 0.3018831861451069], [-0.28080940999901377, 0.9170692258600692, -0.636900175714632, -0.5166066581023038]], [[-0.1622124756351761, 0.18221247563517615], [-0.31146571543844237, 0.2914657154384424], [0.6724191876342267, -0.6524191876342267], [-0.7163255962903853, 0.6963255962903854], [0.420776986348927, -0.40077698634892706]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.04400658379693301\n","h01: 0.0\n","h02: 0.014116589549722613\n","h03: 1.6138101048092222\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.7180748865542411\n","h11: 0.2819251134457588\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.33118142 -1.2661138 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.331181416550594\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.71807489 0.28192511]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.2819251134457589\n","e11: -0.2819251134457588\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.04400658 0.         0.01411659 1.6138101 ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.16998151204997947\n","e01: 0.0\n","e02: -0.3982618477276203\n","e03: 0.23161669695465636\n","\n","[[[-0.1682729071054232, -0.18535655101793833, -0.4381183197644065, 0.1016107968025163], [-0.4113568332773767, -0.6185141114398907, -0.9609841817080558, 0.3285191062948924], [-0.2417136622275185, 0.9170692258600692, -0.5452999507372793, -0.5698784984018748]], [[-0.1340199642906002, 0.15401996429060028], [-0.3102250593255113, 0.29022505932551135], [0.6724191876342267, -0.6524191876342267], [-0.715927614179358, 0.6959276141793581], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.3312918812365684\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.5376456891502086\n","h11: 0.46235431084979134\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.62055551 -0.77142378]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.7714237752217212\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.53764569 0.46235431]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.5376456891502086\n","e11: 0.5376456891502086\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.33129188 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: -0.7122936412838503\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1682729071054232, -0.25658591514632334, -0.4381183197644065, 0.1016107968025163], [-0.4113568332773767, -0.9233757899093786, -0.9609841817080558, 0.3285191062948924], [-0.2417136622275185, 0.6713279196171409, -0.5452999507372793, -0.5698784984018748]], [[-0.18778453320562105, 0.20778453320562112], [-0.3102250593255113, 0.29022505932551135], [0.6546074224544963, -0.6346074224544963], [-0.715927614179358, 0.6959276141793581], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Epoch 16 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.40237738327394\n","h11: 0.59762261672606\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.91036487 -0.5147958 ]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.5147957999525267\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.40237738 0.59762262]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.40237738327394\n","e11: 0.40237738327394\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1682729071054232, -0.25658591514632334, -0.4381183197644065, 0.1016107968025163], [-0.4113568332773767, -0.9233757899093786, -0.9609841817080558, 0.3285191062948924], [-0.2417136622275185, 0.6713279196171409, -0.5452999507372793, -0.5698784984018748]], [[-0.22802227153301505, 0.24802227153301512], [-0.3102250593255113, 0.29022505932551135], [0.6546074224544963, -0.6346074224544963], [-0.715927614179358, 0.6959276141793581], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 2.27872907061733\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9214147908730003\n","h11: 0.07858520912699984\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.08184497 -2.54357178]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.08184497400117405\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.92141479 0.07858521]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.07858520912699973\n","e11: -0.07858520912699984\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         2.27872907 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.10131321819680578\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1682729071054232, -0.24645459332664277, -0.4381183197644065, 0.1016107968025163], [-0.4113568332773767, -0.9305690284013518, -0.9609841817080558, 0.3285191062948924], [-0.2417136622275185, 0.6996956207122466, -0.5452999507372793, -0.5698784984018748]], [[-0.22016375062031507, 0.24016375062031514], [-0.3102250593255113, 0.29022505932551135], [0.67251486251032, -0.65251486251032], [-0.715927614179358, 0.6959276141793581], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.8796669302041059\n","h01: 1.8748890215461929\n","h02: 2.0061332319336254\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.20806815797229714\n","h11: 0.7919318420277028\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.56988957 -0.23327995]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.23327994891674703\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.20806816 0.79193184]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.20806815797229714\n","e11: 0.20806815797229716\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.87966693 1.87488902 2.00613323 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.12493455014196556\n","e01: -0.275696494143584\n","e02: 0.293762116688155\n","e03: 0.0\n","\n","[[[-0.15577945209122665, -0.2740242427410012, -0.40874210809559103, 0.1016107968025163], [-0.44171592896187434, -0.8635747803244609, -1.0323683760632774, 0.3285191062948924], [-0.2442123532303578, 0.7052095505951183, -0.5511751930710425, -0.5698784984018748]], [[-0.24097056641754477, 0.26097056641754485], [-0.32852812710518264, 0.30852812710518274], [0.6335043919987601, -0.6135043919987601], [-0.7576688588009021, 0.7376688588009022], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.043644447472797054\n","h01: 3.2144168624346845\n","h02: 0.10867880057850465\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9649786956565157\n","h11: 0.03502130434348439\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.03564925 -3.35179871]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.03564925492673263\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.9649787 0.0350213]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.03502130434348427\n","e11: -0.03502130434348439\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.04364445 3.21441686 0.1086788  0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.022310540962621327\n","e01: 0.043671874143375464\n","e02: -0.052368677304424016\n","e03: 0.0\n","\n","[[[-0.15801050618748877, -0.2696570553266636, -0.41397897582603344, 0.1016107968025163], [-0.43747692617897627, -0.8718724364117022, -1.0224183273754368, 0.3285191062948924], [-0.25005771496256457, 0.7166515816206827, -0.5648957865248015, -0.5698784984018748]], [[-0.23746843598319634, 0.2574684359831964], [-0.32837527855739784, 0.30837527855739794], [0.6447616991213754, -0.6247616991213754], [-0.7572882514658276, 0.7372882514658277], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.6130974309578027\n","h01: 3.004585592333104\n","h02: 1.4160593340721273\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6926751292521414\n","h11: 0.30732487074785864\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.36719418 -1.17984988]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.36719417866607923\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.69267513 0.30732487]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.30732487074785864\n","e11: -0.30732487074785864\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.61309743 3.00458559 1.41605933 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.1956892826639316\n","e01: 0.3901561142763357\n","e02: -0.4593205305862575\n","e03: 0.0\n","\n","[[[-0.17757943445388194, -0.23064144389903005, -0.4599110288846592, 0.1016107968025163], [-0.3869890912516819, -0.9725327138949968, -0.9039136304841824, 0.3285191062948924], [-0.2780412823835068, 0.7724439059621987, -0.6305786223986364, -0.5698784984018748]], [[-0.20673594890841046, 0.22673594890841053], [-0.30953326968490275, 0.28953326968490284], [0.7371000870028404, -0.7171000870028403], [-0.713769226284326, 0.6937692262843261], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 1.2193034691352638\n","h01: 2.91203478827026\n","h02: 2.7981573792757457\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.29572302498029723\n","h11: 0.7042769750197027\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.21833199 -0.35058357]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.3505835697718372\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.29572302 0.70427698]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.29572302498029723\n","e11: 0.29572302498029734\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[1.21930347 2.91203479 2.79815738 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.17715776918691728\n","e01: -0.4300404743838346\n","e02: 0.41624152896968847\n","e03: 0.0\n","\n","[[[-0.15986365753519022, -0.2736454913374135, -0.4182868759876903, 0.1016107968025163], [-0.44775420608279454, -0.8250288311813416, -1.0466844749207855, 0.3285191062948924], [-0.2824702266131797, 0.7831949178217945, -0.6409846606228786, -0.5698784984018748]], [[-0.23630825140644018, 0.25630825140644026], [-0.3455908807110678, 0.3255908807110679], [0.6509845133593263, -0.6309845133593263], [-0.7965171827413625, 0.7765171827413626], [0.4662743460367522, -0.44627434603675226]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 1.7901283153659544\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.757856357211736\n","h11: 0.24214364278826397\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.27726141 -1.41822416]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.27726141365679347\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.75785636 0.24214364]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.24214364278826395\n","e11: -0.24214364278826397\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         0.         0.         1.79012832]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.22096786452034414\n","\n","[[[-0.15986365753519022, -0.2736454913374135, -0.4182868759876903, 0.12370758325455072], [-0.44775420608279454, -0.8250288311813416, -1.0466844749207855, 0.35393041071473197], [-0.2824702266131797, 0.7831949178217945, -0.6409846606228786, -0.6207011072415539]], [[-0.2120938871276138, 0.23209388712761386], [-0.3455908807110678, 0.3255908807110679], [0.6509845133593263, -0.6309845133593263], [-0.7965171827413625, 0.7765171827413626], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.3907435601256737\n","h11: 0.6092564398743263\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.93970379 -0.49551602]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.49551601636555137\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.39074356 0.60925644]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.3907435601256737\n","e11: 0.3907435601256737\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.15986365753519022, -0.2736454913374135, -0.4182868759876903, 0.12370758325455072], [-0.44775420608279454, -0.8250288311813416, -1.0466844749207855, 0.35393041071473197], [-0.2824702266131797, 0.7831949178217945, -0.6409846606228786, -0.6207011072415539]], [[-0.25116824314018116, 0.27116824314018123], [-0.3455908807110678, 0.3255908807110679], [0.6509845133593263, -0.6309845133593263], [-0.7965171827413625, 0.7765171827413626], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Epoch 17 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.3723060475583654\n","h11: 0.6276939524416346\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.98803905 -0.46570257]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.4657025681775264\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.37230605 0.62769395]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.3723060475583654\n","e11: 0.3723060475583654\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.15986365753519022, -0.2736454913374135, -0.4182868759876903, 0.12370758325455072], [-0.44775420608279454, -0.8250288311813416, -1.0466844749207855, 0.35393041071473197], [-0.2824702266131797, 0.7831949178217945, -0.6409846606228786, -0.6207011072415539]], [[-0.2883988478960177, 0.3083988478960178], [-0.3455908807110678, 0.3255908807110679], [0.6509845133593263, -0.6309845133593263], [-0.7965171827413625, 0.7765171827413626], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 2.5050707487023636\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9317969355673262\n","h11: 0.06820306443267367\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.07064037 -2.68526578]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.07064036832847352\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.93179694 0.06820306]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.06820306443267377\n","e11: -0.06820306443267367\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         2.50507075 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.08743421612998428\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.15986365753519022, -0.2649020697244151, -0.4182868759876903, 0.12370758325455072], [-0.44775420608279454, -0.8312366605265705, -1.0466844749207855, 0.35393041071473197], [-0.2824702266131797, 0.8076764983381901, -0.6409846606228786, -0.6207011072415539]], [[-0.28157854145275035, 0.3015785414527504], [-0.3455908807110678, 0.3255908807110679], [0.6680698635275416, -0.6480698635275416], [-0.7965171827413625, 0.7765171827413626], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.9846731085686364\n","h01: 1.5934677156875134\n","h02: 2.253353330194394\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.0634810823722744\n","h11: 0.9365189176277255\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-2.75701333 -0.06558556]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.06558555695207098\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.06348108 0.93651892]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.0634810823722744\n","e11: 0.06348108237227446\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.98467311 1.59346772 2.25335333 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.042607344683606836\n","e01: -0.08354997442660653\n","e02: 0.09985792412962731\n","e03: 0.0\n","\n","[[[-0.15560292306682955, -0.27325706716707576, -0.4083010835747276, 0.12370758325455072], [-0.458107790840911, -0.8109340167409052, -1.070949950484285, 0.35393041071473197], [-0.28332237350685185, 0.8093474978267222, -0.6429818191054711, -0.6207011072415539]], [[-0.2879266496899778, 0.30792664968997785], [-0.35184169218254874, 0.33184169218254883], [0.6579543579958297, -0.6379543579958297], [-0.8108217135781535, 0.7908217135781536], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 3.388008008946656\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9780049178607206\n","h11: 0.021995082139279337\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.02224058 -3.81693639]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.022240580472518107\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.97800492 0.02199508]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.021995082139279365\n","e11: -0.021995082139279337\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         3.38800801 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.028503618653244585\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.15560292306682955, -0.2704067053017513, -0.4083010835747276, 0.12370758325455072], [-0.458107790840911, -0.8163497042850216, -1.070949950484285, 0.35393041071473197], [-0.28332237350685185, 0.8168154459138723, -0.6429818191054711, -0.6207011072415539]], [[-0.28572714147604983, 0.3057271414760499], [-0.35184169218254874, 0.33184169218254883], [0.6654063094403615, -0.6454063094403615], [-0.8108217135781535, 0.7908217135781536], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.6211641831879227\n","h01: 3.003821619410442\n","h02: 1.4352857873539044\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.6507863122362052\n","h11: 0.34921368776379486\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.42957394 -1.05207126]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.4295739360707804\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.65078631 0.34921369]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.3492136877637948\n","e11: -0.34921368776379486\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.62116418 3.00382162 1.43528579 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.2387515959169677\n","e01: 0.457753708606655\n","e02: -0.559315807679897\n","e03: 0.0\n","\n","[[[-0.17947808265852633, -0.22463133444108582, -0.4642326643427173, 0.12370758325455072], [-0.39650987909433333, -0.9344501611055386, -0.9266464721028715, 0.35393041071473197], [-0.31746385172297825, 0.882274226244624, -0.7229639796036964, -0.6207011072415539]], [[-0.25080577269967036, 0.27080577269967043], [-0.3301497886707647, 0.3101497886707648], [0.770303871950255, -0.7503038719502549], [-0.7606995692984716, 0.7406995692984717], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 1.2599167655657817\n","h01: 2.7599641615897554\n","h02: 2.894905729871056\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.18574152283943934\n","h11: 0.8142584771605605\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.68339923 -0.20547742]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.20547742387530848\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.18574152 0.81425848]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.18574152283943934\n","e11: 0.18574152283943945\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[1.25991677 2.75996416 2.89490573 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.1189302185688651\n","e01: -0.282439997993525\n","e02: 0.27887216239281876\n","e03: 0.0\n","\n","[[[-0.16758506080163982, -0.25287533424043834, -0.43634544810343545, 0.12370758325455072], [-0.43730294406345405, -0.8375732417937595, -1.0222996238036084, 0.35393041071473197], [-0.32043710718719987, 0.8893352261944621, -0.7299357836635169, -0.6207011072415539]], [[-0.2693799249836143, 0.28937992498361437], [-0.35355167453947767, 0.33355167453947776], [0.7190398773146592, -0.6990398773146591], [-0.8144699891727585, 0.7944699891727586], [0.5096211651708653, -0.4896211651708653]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.06652190005594771\n","h01: 0.0\n","h02: 0.0668622869485036\n","h03: 1.9583401022320663\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.7764004410459039\n","h11: 0.22359955895409617\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.25308686 -1.49789851]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.2530868596221368\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.77640044 0.22359956]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.2235995589540961\n","e11: -0.22359955895409617\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.0665219  0.         0.06686229 1.9583401 ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.1536360058099368\n","e01: 0.0\n","e02: -0.3597582695416706\n","e03: 0.2234301443526742\n","\n","[[[-0.1829486613826335, -0.25287533424043834, -0.4723212750576025, 0.14605059768981815], [-0.45497108473159675, -0.8375732417937595, -1.0636718248009005, 0.3796248773152895], [-0.2851008258509144, 0.8893352261944621, -0.6471913816689326, -0.672090040442669]], [[-0.24701996908820467, 0.26701996908820474], [-0.3520642477881478, 0.3320642477881479], [0.7190398773146592, -0.6990398773146591], [-0.8129749513855237, 0.7929749513855238], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.37424694827654986\n","h11: 0.6257530517234501\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.98283941 -0.46879947]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.46879947177691167\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.37424695 0.62575305]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.37424694827654986\n","e11: 0.3742469482765499\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1829486613826335, -0.25287533424043834, -0.4723212750576025, 0.14605059768981815], [-0.45497108473159675, -0.8375732417937595, -1.0636718248009005, 0.3796248773152895], [-0.2851008258509144, 0.8893352261944621, -0.6471913816689326, -0.672090040442669]], [[-0.28444466391585965, 0.3044446639158597], [-0.3520642477881478, 0.3320642477881479], [0.7190398773146592, -0.6990398773146591], [-0.8129749513855237, 0.7929749513855238], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Epoch 18 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.3568897346338846\n","h11: 0.6431102653661155\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.03032841 -0.44143908]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.4414390836516339\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.35688973 0.64311027]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.3568897346338846\n","e11: 0.3568897346338845\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1829486613826335, -0.25287533424043834, -0.4723212750576025, 0.14605059768981815], [-0.45497108473159675, -0.8375732417937595, -1.0636718248009005, 0.3796248773152895], [-0.2851008258509144, 0.8893352261944621, -0.6471913816689326, -0.672090040442669]], [[-0.3201336373792481, 0.3401336373792482], [-0.3520642477881478, 0.3320642477881479], [0.7190398773146592, -0.6990398773146591], [-0.8129749513855237, 0.7929749513855238], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 2.8319403007776245\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.966289363672798\n","h11: 0.03371063632720197\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.03429194 -3.38994187]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.03429194130973239\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.96628936 0.03371064]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.03371063632720195\n","e11: -0.03371063632720197\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.        2.8319403 0.        0.       ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.04780437089127674\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1829486613826335, -0.24809489715131067, -0.4723212750576025, 0.14605059768981815], [-0.45497108473159675, -0.8409673521270401, -1.0636718248009005, 0.3796248773152895], [-0.2851008258509144, 0.9027204500440197, -0.6471913816689326, -0.672090040442669]], [[-0.3167625737465279, 0.33676257374652796], [-0.3520642477881478, 0.3320642477881479], [0.7285865282726454, -0.7085865282726452], [-0.8129749513855237, 0.7929749513855238], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.9796512396853296\n","h01: 1.6149116785085929\n","h02: 2.2418395355423724\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.06893873254154832\n","h11: 0.9310612674584516\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-2.6745371 -0.0714302]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.07143019564428728\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.06893873 0.93106127]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.06893873254154832\n","e11: 0.06893873254154836\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.97965124 1.61491168 2.24183954 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.047162951380586085\n","e01: -0.09907688896109532\n","e02: 0.1107121508222588\n","e03: 0.0\n","\n","[[[-0.1782323662445749, -0.2580025860474202, -0.46125005997537666, 0.14605059768981815], [-0.4664316819170792, -0.816891668109494, -1.0905748774507094, 0.3796248773152895], [-0.2860440848785261, 0.9047019878232416, -0.6494056246853778, -0.672090040442669]], [[-0.32365644700068275, 0.3436564470006828], [-0.35881783926781413, 0.3388178392678142], [0.7174535318443527, -0.6974535318443525], [-0.8284299089997061, 0.8084299089997062], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 3.6644107914575117\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.989201467982704\n","h11: 0.010798532017296051\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.01085726 -4.52834508]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.010857259325964893\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.98920147 0.01079853]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.01079853201729597\n","e11: -0.010798532017296051\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         3.66441079 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.015278919228740768\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.1782323662445749, -0.25647469412454615, -0.46125005997537666, 0.14605059768981815], [-0.4664316819170792, -0.8197946627629548, -1.0905748774507094, 0.3796248773152895], [-0.2860440848785261, 0.9087050646611717, -0.6494056246853778, -0.672090040442669]], [[-0.32257659379895315, 0.3425765937989532], [-0.35881783926781413, 0.3388178392678142], [0.7214105575699605, -0.7014105575699605], [-0.8284299089997061, 0.8084299089997062], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Building batch 5\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.6161183317251971\n","h01: 3.1580437782693527\n","h02: 1.423783080547363\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.7441818788687229\n","h11: 0.2558181211312771\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.29546981 -1.36328855]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.2954698131796711\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.74418188 0.25581812]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.2558181211312771\n","e11: -0.2558181211312771\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.61611833 3.15804378 1.42378308 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.17846784851712805\n","e01: 0.36398342438100306\n","e02: -0.4187384031958939\n","e03: 0.0\n","\n","[[[-0.1960791510962877, -0.22007635168644585, -0.503123900294966, 0.14605059768981815], [-0.42038697699966016, -0.9137023862532535, -0.9825403694261687, 0.3796248773152895], [-0.3115649872164754, 0.9607546943476551, -0.7092852163423906, -0.672090040442669]], [[-0.29699478168582544, 0.3169947816858255], [-0.3430564158661664, 0.3230564158661665], [0.8021990401506791, -0.7821990401506791], [-0.7920069577432933, 0.7720069577432934], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Building batch 6\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 1.3237394268166656\n","h01: 2.6737341595753\n","h02: 3.0443108709223905\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.11703271107566074\n","h11: 0.8829672889243393\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-2.1453018  -0.12446712]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.12446712445017351\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.11703271 0.88296729]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.11703271107566074\n","e11: 0.11703271107566071\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[1.32373943 2.67373416 3.04431087 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.07795699057992034\n","e01: -0.18542640276074035\n","e02: 0.18304078868945456\n","e03: 0.0\n","\n","[[[-0.18828345203829566, -0.23861899196251987, -0.48481982142602054, 0.14605059768981815], [-0.44712622476857283, -0.8501011301063196, -1.0453233599466516, 0.3796248773152895], [-0.3135139119809734, 0.9653903544166736, -0.7138612360596269, -0.672090040442669]], [[-0.3086980527933915, 0.3286980527933916], [-0.358548497253976, 0.33854849725397607], [0.770907604411609, -0.750907604411609], [-0.8276353532014087, 0.8076353532014088], [0.5534095634849863, -0.5334095634849862]]]\n","[●] Building batch 7\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.018603387034084262\n","h01: 0.0\n","h02: 0.0\n","h03: 2.128426299620539\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.8406202029966975\n","h11: 0.1593797970033024\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.17361532 -1.83646526]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.17361532268054522\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.8406202 0.1593798]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.15937979700330251\n","e11: -0.1593797970033024\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.01860339 0.         0.         2.1284263 ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: -0.11110317747628964\n","e01: 0.0\n","e02: 0.0\n","e03: 0.17321701183578064\n","\n","[[[-0.19939376978592463, -0.23861899196251987, -0.48481982142602054, 0.16337229887339622], [-0.45990309017834613, -0.8501011301063196, -1.0453233599466516, 0.39954483367640425], [-0.2879601811614268, 0.9653903544166736, -0.7138612360596269, -0.7119299531648985]], [[-0.2927600730930613, 0.31276007309306136], [-0.35825199684906933, 0.3382519968490694], [0.770907604411609, -0.750907604411609], [-0.8276353532014087, 0.8076353532014088], [0.5873323786419875, -0.5673323786419874]]]\n","[●] Building batch 8\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.35308178915316857\n","h11: 0.6469182108468314\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.04105555 -0.43553541]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.4355354053826379\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.35308179 0.64691821]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.35308178915316857\n","e11: 0.35308178915316857\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.19939376978592463, -0.23861899196251987, -0.48481982142602054, 0.16337229887339622], [-0.45990309017834613, -0.8501011301063196, -1.0453233599466516, 0.39954483367640425], [-0.2879601811614268, 0.9653903544166736, -0.7138612360596269, -0.7119299531648985]], [[-0.32806825200837814, 0.3480682520083782], [-0.35825199684906933, 0.3382519968490694], [0.770907604411609, -0.750907604411609], [-0.8276353532014087, 0.8076353532014088], [0.5873323786419875, -0.5673323786419874]]]\n","[●] Epoch 19 ========================================\n","[●] Building batch 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 0.0\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.33712413963003657\n","h11: 0.6628758603699634\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-1.08730405 -0.41116755]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.41116754558872376\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.33712414 0.66287586]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.33712413963003657\n","e11: 0.3371241396300366\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0. 0. 0. 0.]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.0\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.19939376978592463, -0.23861899196251987, -0.48481982142602054, 0.16337229887339622], [-0.45990309017834613, -0.8501011301063196, -1.0453233599466516, 0.39954483367640425], [-0.2879601811614268, 0.9653903544166736, -0.7138612360596269, -0.7119299531648985]], [[-0.3617806659713818, 0.3817806659713819], [-0.35825199684906933, 0.3382519968490694], [0.770907604411609, -0.750907604411609], [-0.8276353532014087, 0.8076353532014088], [0.5873323786419875, -0.5673323786419874]]]\n","[●] Building batch 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 3.068045802779653\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9806483724822931\n","h11: 0.019351627517707016\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.01954132 -3.94497875]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.01954132150757223\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.98064837 0.01935163]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.019351627517706915\n","e11: -0.019351627517707016\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.        3.0680458 0.        0.       ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.029449601071928354\n","e02: 0.0\n","e03: 0.0\n","\n","[[[-0.19939376978592463, -0.23567403185532704, -0.48481982142602054, 0.16337229887339622], [-0.45990309017834613, -0.8521920517824265, -1.0453233599466516, 0.39954483367640425], [-0.2879601811614268, 0.9736362427168136, -0.7138612360596269, -0.7119299531648985]], [[-0.3598455032196111, 0.3798455032196112], [-0.35825199684906933, 0.3382519968490694], [0.7768447723698746, -0.7568447723698746], [-0.8276353532014087, 0.8076353532014088], [0.5873323786419875, -0.5673323786419874]]]\n","[●] Building batch 3\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.975762775579742\n","h01: 1.6404254054326068\n","h02: 2.198088190456269\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.07600696090364993\n","h11: 0.9239930390963501\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-2.57693035 -0.07905074]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.07905074081433798\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.07600696 0.92399304]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: -0.07600696090364993\n","e11: 0.07600696090364989\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.97576278 1.64042541 2.19808819 0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.05293915181825046\n","e01: -0.11657108126537075\n","e02: 0.12429195664844292\n","e03: 0.0\n","\n","[[[-0.1940998546040996, -0.24733113998186412, -0.47239062576117624, 0.16337229887339622], [-0.47276730407018097, -0.8238652790349414, -1.0755263054122233, 0.39954483367640425], [-0.28901896419779183, 0.975967664342121, -0.7163470751925958, -0.7119299531648985]], [[-0.36744619930997613, 0.3874461993099762], [-0.365668473162542, 0.34566847316254207], [0.7643763974042675, -0.7443763974042675], [-0.8443423535168871, 0.8243423535168872], [0.5873323786419875, -0.5673323786419874]]]\n","[●] Building batch 4\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 0.0\n","h01: 3.8750481707608815\n","h02: 0.0\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 2\n","Activation function: softmax\n","h10: 0.9938893781010459\n","h11: 0.00611062189895405\n","\n","[●] Calculating Loss for layer 1\n","Output log: [-0.00612937 -5.09772673]\n","[✔] Successfully calculated Loss for layer 1\n","Loss: 0.006129368155488845\n","\n","[✔] Successfully evaluated data 1\n","[●] Calculating Error Node Output for data 1 in layer 1\n","[0.99388938 0.00611062]\n","[●] Calculating Error Node Output for layer 1\n","[✔] Successfully calculated Error Node Output for layer 1\n","e10: 0.006110621898954061\n","e11: -0.00611062189895405\n","\n","[●] Calculating Error Node Output for data 1 in layer 0\n","[0.         3.87504817 0.         0.        ]\n","[●] Calculating Error Node Output for layer 0\n","[✔] Successfully calculated Error Node Output for layer 0\n","e00: 0.0\n","e01: 0.009219417868065169\n","e02: 0.0\n","e03: 0.0\n","\n","[✔] Loss threshold reached\n"]}],"source":["# Input\n","model_json = Driver.load_model(model_file)\n","\n","# Initialize FFNN\n","model = FFNN(model_json)\n","\n","# Build FNN\n","model.build()\n","\n","# Test the output\n","# model.test()\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ad693be4-3a1e-4be5-9f4f-9f4a320647d1' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"61f060aabad042bcb878ee344004af04","deepnote_persisted_session":{"createdAt":"2024-03-30T06:15:23.462Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
