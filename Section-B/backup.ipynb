{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"bb504219aad64c9ea3fd5f80ae240ce9","deepnote_cell_type":"text-cell-h1","formattedRanges":[]},"source":["# Tugas Besar 1 Machine Learning"]},{"cell_type":"markdown","metadata":{"cell_id":"cccd3ddc8c7d471f8f8de7880bc8732c","deepnote_cell_type":"markdown"},"source":["## About\n","Feedforward Neural Network algorithm with rectified linear unit (ReLU) and sigmoid activation function.\n","\n","### Features\n","\n","### Usage\n","\n","### Tech stack\n","* ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)\n","\n","## Author\n","| Name | NIM |\n","| :--- | :---: |\n","| Angger Ilham Amanullah | 13521001 |\n","| Kelvin Rayhan Alkarim | 13521005 |\n","| Ditra Rizqa Amadia | 13521019 |\n","| Bernardus Willson | 13521021 |"]},{"cell_type":"markdown","metadata":{"cell_id":"fc87ca933e3c4795a4e87231e828012c","deepnote_cell_type":"separator"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"cell_id":"8cbf9e0cf0db4e89999ee957f789d882","deepnote_cell_type":"text-cell-callout","formattedRanges":[]},"source":["> Make sure required modules are imported"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"d288ab750b614db7a2d8ff2bdc4aa4db","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1711813803986,"source_hash":null},"outputs":[],"source":["# Modules\n","import json\n","import numpy as np\n","from graphviz import Digraph, Source\n","from IPython.display import display\n","import pickle\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"cell_id":"10c2e6e558fa4fcab00df3eaa208a157","deepnote_cell_type":"markdown"},"source":["### Classes"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"06cbdeb956d44a469343c389a447535e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1711813803987,"source_hash":null},"outputs":[],"source":["class Driver:\n","    @staticmethod\n","    def terminate(code):\n","        print(f\"[■] Program terminated with code {code}\")\n","        quit(code)\n","\n","    @staticmethod\n","    def load_model(model_file):\n","        try:\n","            model = json.load(open(model_file, \"r\"))\n","        except:\n","            print(f\"[✖] Error loading model from '{model_file}'\")\n","            print(\"\")\n","\n","            Driver.terminate(1)        \n","            \n","        print(f\"[✔] Successfully loaded model from '{model_file}'\")\n","        print(\"\")\n","\n","        return model\n","\n","    @staticmethod\n","    def load_data(data_file):\n","        try:\n","            data = pd.read_csv(data_file)\n","        except:\n","            print(f\"[✖] Error loading data from '{data_file}'\")\n","            print(\"\")\n","\n","            Driver.terminate(1)        \n","            \n","        print(f\"[✔] Successfully loaded data from '{data_file}'\")\n","        print(\"\")\n","\n","        return data"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"9f49d935bea74ab4a472c1c166e849c9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":39,"execution_start":1711813803988,"source_hash":null},"outputs":[],"source":["class Layer:\n","    # Initialize layer\n","    def __init__(self, id, layer, weight, input):\n","        try:\n","            self._id = id\n","            self._num_of_neuron = layer[\"number_of_neurons\"]\n","            self._activation_function = layer[\"activation_function\"]\n","            self._weight = weight\n","            self._input = input       \n","            self._input = np.insert(self._input, 0, 1) # Append bias of 1\n","            self._sigma = np.zeros(self._num_of_neuron)\n","            self._output = np.zeros(self._num_of_neuron)\n","        except:\n","            print(f\"[✖] Error initialiazing layer\")\n","            print(\"\")\n","\n","            Driver.terminate(1)\n","\n","    # Calculate sigma\n","    def _calculate_sigma(self, i):\n","        for j in range(len(self._input)):\n","            self._sigma[i] += self._input[j] * self._weight[j][i]\n","\n","    # Calculate activation\n","    def _calculate_activation(self, i):\n","        if self._activation_function == 'relu':\n","            self._output[i] = max(0, self._sigma[i])\n","        elif self._activation_function == 'sigmoid':\n","            self._output[i] = 1 / (1 + np.exp(-self._sigma[i]))\n","        elif self._activation_function == 'linear':\n","            self._output[i] = self._sigma[i]\n","        elif self._activation_function == 'softmax':\n","            exp_values = np.exp(self._sigma - np.max(self._sigma))\n","            self._output = exp_values / np.sum(exp_values)\n","\n","    # Calculate derivative\n","    def _calculate_derivative(self, i):\n","        if self._activation_function == 'relu':\n","            if self._sigma[i] > 0:\n","                return 1\n","            else:\n","                return 0\n","        elif self._activation_function == 'sigmoid':\n","            return self._output[i] * (1 - self._output[i])\n","        elif self._activation_function == 'linear':\n","            return 1\n","        # TODO\n","        elif self._activation_function == 'softmax':\n","            return 0\n","\n","    # Calculate forward\n","    def _calculate_forward(self):\n","        print(f\"[●] Building layer {self._id}\")\n","\n","        # For each neuron, calculate its activation\n","        for i in range(self._num_of_neuron):\n","            self._calculate_sigma(i)\n","            self._calculate_activation(i)\n","\n","        print(f\"[✔] Successfully built layer {self._id}\")\n","        print(f\"Number of neurons: {self._num_of_neuron}\")\n","        print(f\"Activation function: {self._activation_function}\")\n","        for i in range(len(self._output)):\n","            print(f\"h{self._id}{i}: {self._output[i]}\")\n","        print(\"\")\n","        \n","        return self._output\n","\n","    # Calculate backward\n","    def _calculate_backward(self, error, learning_rate):\n","        print(f\"[●] Backpropagating layer {self._id}\")\n","\n","        "]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"b19fca533a574742a2de0b3b4d62cf61","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":264,"execution_start":1711813804006,"source_hash":null},"outputs":[],"source":["class FFNN:\n","    # Initialize model\n","    def __init__(self, model, x, y):\n","        try:\n","            self._layers = model[\"case\"][\"model\"][\"layers\"]\n","            self._weights = model[\"case\"][\"weights\"]\n","            self._inputs = x\n","            self._outputs = []\n","            self._outputs\n","            self._expect = y\n","            self.batch_size = 3\n","        except:\n","            print(f\"[✖] Error initialiazing model\")\n","            print(\"\")\n","\n","            Driver.terminate(1)\n","        \n","        print(f\"[✔] Successfully initialized model\")\n","        print(f\"Number of features: {len(self._inputs[0])}\")\n","        print(f\"Number of layers: {len(self._layers)}\")\n","        print(f\"Number of data: {len(self._inputs)}\")\n","        print(\"\")\n","\n","    # Assert the output with the expected output\n","    def test(self):\n","        print(f\"[●] Asserting output =======================================\")\n","\n","        passed_output = 0\n","        for i in range(len(self._inputs)):\n","            if (np.all(self._expect['output'][i] < self._outputs[i] + self._expect['max_sse']) or np.all(self._expect['output'][i] > self._outputs[i] - self._expect['max_sse'])):\n","                passed_output += 1\n","\n","        print(f\"Test status: {'FAIL' if passed_output != len(self._inputs) else 'PASS'}\")\n","        print(f\"Test result: {passed_output}/{len(self._inputs)}\")\n","        print(\"\")\n","    \n","    # Build the network\n","    def build(self):\n","        np.random.seed(42)\n","        one_hot_encoder = OneHotEncoder()\n","        y_encoded = one_hot_encoder.fit_transform(y.reshape(-1, 1)).toarray()\n","\n","        # Loop until max epoch\n","        for epoch in range(5):\n","            print(f\"[●] Epoch {epoch + 1} ========================================\")\n","\n","            # Shuffle data\n","            indices = np.arange(len(self._inputs))\n","            np.random.shuffle(indices)\n","            X_shuffled = self._inputs[indices]\n","            y_shuffled = y_encoded[indices]\n","\n","            # Split data into batches\n","            for batch_start in range(0, len(self._inputs), self.batch_size):\n","                X_batch = X_shuffled[batch_start:batch_start + self.batch_size]\n","                y_batch = y_shuffled[batch_start:batch_start + self.batch_size]\n","\n","                print(X_batch)\n","\n","                # For each data in batch, calculate output\n","                for i in range(len(X_batch)):\n","                    _in = X_batch[i]\n","\n","                    # Feed forward\n","                    for j in range(len(self._layers)):\n","                        \n","                        # Create layer\n","                        layer = Layer(j, self._layers[j], self._weights[j], _in)\n","\n","                        # Calculate forward\n","                        _in = layer._calculate_forward()\n","\n","                    self._outputs.append(_in)\n","                    print(f\"[✔] Successfully evaluated data {i + 1}\")\n","\n","                # Backpropagation (TODO)\n","                error = y_batch[i] - _in\n","                for j in range(len(self._layers) - 1, -1, -1):\n","                    layer = Layer(j, self._layers[j], self._weights[j], _in)\n","                    error = layer._calculate_backward(error, 0.01)\n","\n","                print(f\"[✔] Successfully evaluated batch {batch_start + 1}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"cell_id":"516ba36dce3345e78882c74b46308a0b","deepnote_cell_type":"input-file","deepnote_to_be_reexecuted":false,"deepnote_variable_name":"model_file","deepnote_variable_value":"file_input_uploads/multilayer-20240330-154837.json","execution_millis":264,"execution_start":1711813804007,"source_hash":null},"outputs":[],"source":["model_file = 'models/modified_multilayer.json'\n","data_file = 'models/tes.csv'"]},{"cell_type":"code","execution_count":24,"metadata":{"cell_id":"00e313cbf76b4aab826f4ebebef495e3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":281,"execution_start":1711813804008,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["[✔] Successfully loaded model from 'models/modified_multilayer.json'\n","\n","[✔] Successfully loaded data from 'models/tes.csv'\n","\n","[✔] Successfully initialized model\n","Number of features: 4\n","Number of layers: 2\n","Number of data: 8\n","\n","[●] Epoch 1 ========================================\n","[[5.1 3.5 1.4 0.2]\n"," [6.4 3.2 4.5 1.5]\n"," [6.9 3.1 4.9 1.5]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.48\n","h01: 8.78\n","h02: 2.1599999999999984\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.330000000000001\n","h01: 13.989999999999998\n","h02: 8.309999999999999\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.510000000000001\n","h01: 14.75\n","h02: 9.370000000000001\n","h03: 0.24000000000000005\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 1\n","[[6.3 3.3 6.  2.5]\n"," [5.8 2.7 5.1 1.9]\n"," [6.3 2.9 5.6 1.8]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 7.220000000000001\n","h01: 16.43\n","h02: 10.579999999999998\n","h03: 0.2500000000000002\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.88\n","h01: 14.09\n","h02: 9.42\n","h03: 0.2699999999999998\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 6.4799999999999995\n","h01: 15.259999999999998\n","h02: 10.279999999999998\n","h03: 0.33000000000000007\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 4\n","[[4.7 3.2 1.3 0.2]\n"," [7.  3.2 4.7 1.4]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.2800000000000002\n","h01: 8.100000000000001\n","h02: 2.0599999999999996\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.3100000000000005\n","h01: 14.6\n","h02: 9.01\n","h03: 0.12999999999999962\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[✔] Successfully evaluated batch 7\n","[●] Epoch 2 ========================================\n","[[4.7 3.2 1.3 0.2]\n"," [6.3 3.3 6.  2.5]\n"," [6.9 3.1 4.9 1.5]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.2800000000000002\n","h01: 8.100000000000001\n","h02: 2.0599999999999996\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 7.220000000000001\n","h01: 16.43\n","h02: 10.579999999999998\n","h03: 0.2500000000000002\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.510000000000001\n","h01: 14.75\n","h02: 9.370000000000001\n","h03: 0.24000000000000005\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 1\n","[[6.3 2.9 5.6 1.8]\n"," [6.4 3.2 4.5 1.5]\n"," [5.8 2.7 5.1 1.9]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 6.4799999999999995\n","h01: 15.259999999999998\n","h02: 10.279999999999998\n","h03: 0.33000000000000007\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.330000000000001\n","h01: 13.989999999999998\n","h02: 8.309999999999999\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.88\n","h01: 14.09\n","h02: 9.42\n","h03: 0.2699999999999998\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 4\n","[[5.1 3.5 1.4 0.2]\n"," [7.  3.2 4.7 1.4]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.48\n","h01: 8.78\n","h02: 2.1599999999999984\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.3100000000000005\n","h01: 14.6\n","h02: 9.01\n","h03: 0.12999999999999962\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[✔] Successfully evaluated batch 7\n","[●] Epoch 3 ========================================\n","[[6.9 3.1 4.9 1.5]\n"," [7.  3.2 4.7 1.4]\n"," [4.7 3.2 1.3 0.2]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.510000000000001\n","h01: 14.75\n","h02: 9.370000000000001\n","h03: 0.24000000000000005\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.3100000000000005\n","h01: 14.6\n","h02: 9.01\n","h03: 0.12999999999999962\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.2800000000000002\n","h01: 8.100000000000001\n","h02: 2.0599999999999996\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 1\n","[[5.1 3.5 1.4 0.2]\n"," [6.3 2.9 5.6 1.8]\n"," [6.4 3.2 4.5 1.5]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.48\n","h01: 8.78\n","h02: 2.1599999999999984\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 6.4799999999999995\n","h01: 15.259999999999998\n","h02: 10.279999999999998\n","h03: 0.33000000000000007\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.330000000000001\n","h01: 13.989999999999998\n","h02: 8.309999999999999\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 4\n","[[5.8 2.7 5.1 1.9]\n"," [6.3 3.3 6.  2.5]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.88\n","h01: 14.09\n","h02: 9.42\n","h03: 0.2699999999999998\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 7.220000000000001\n","h01: 16.43\n","h02: 10.579999999999998\n","h03: 0.2500000000000002\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[✔] Successfully evaluated batch 7\n","[●] Epoch 4 ========================================\n","[[6.4 3.2 4.5 1.5]\n"," [5.8 2.7 5.1 1.9]\n"," [6.3 3.3 6.  2.5]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.330000000000001\n","h01: 13.989999999999998\n","h02: 8.309999999999999\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.88\n","h01: 14.09\n","h02: 9.42\n","h03: 0.2699999999999998\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 7.220000000000001\n","h01: 16.43\n","h02: 10.579999999999998\n","h03: 0.2500000000000002\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 1\n","[[7.  3.2 4.7 1.4]\n"," [6.9 3.1 4.9 1.5]\n"," [6.3 2.9 5.6 1.8]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.3100000000000005\n","h01: 14.6\n","h02: 9.01\n","h03: 0.12999999999999962\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.510000000000001\n","h01: 14.75\n","h02: 9.370000000000001\n","h03: 0.24000000000000005\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 6.4799999999999995\n","h01: 15.259999999999998\n","h02: 10.279999999999998\n","h03: 0.33000000000000007\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 4\n","[[4.7 3.2 1.3 0.2]\n"," [5.1 3.5 1.4 0.2]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.2800000000000002\n","h01: 8.100000000000001\n","h02: 2.0599999999999996\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.48\n","h01: 8.78\n","h02: 2.1599999999999984\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[✔] Successfully evaluated batch 7\n","[●] Epoch 5 ========================================\n","[[5.1 3.5 1.4 0.2]\n"," [6.3 3.3 6.  2.5]\n"," [7.  3.2 4.7 1.4]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.48\n","h01: 8.78\n","h02: 2.1599999999999984\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 7.220000000000001\n","h01: 16.43\n","h02: 10.579999999999998\n","h03: 0.2500000000000002\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.3100000000000005\n","h01: 14.6\n","h02: 9.01\n","h03: 0.12999999999999962\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 1\n","[[5.8 2.7 5.1 1.9]\n"," [6.4 3.2 4.5 1.5]\n"," [6.9 3.1 4.9 1.5]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.88\n","h01: 14.09\n","h02: 9.42\n","h03: 0.2699999999999998\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.330000000000001\n","h01: 13.989999999999998\n","h02: 8.309999999999999\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 5.510000000000001\n","h01: 14.75\n","h02: 9.370000000000001\n","h03: 0.24000000000000005\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 3\n","[✔] Successfully evaluated batch 4\n","[[4.7 3.2 1.3 0.2]\n"," [6.3 2.9 5.6 1.8]]\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 2.2800000000000002\n","h01: 8.100000000000001\n","h02: 2.0599999999999996\n","h03: 0.0\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 1\n","[●] Building layer 0\n","[✔] Successfully built layer 0\n","Number of neurons: 4\n","Activation function: relu\n","h00: 6.4799999999999995\n","h01: 15.259999999999998\n","h02: 10.279999999999998\n","h03: 0.33000000000000007\n","\n","[●] Building layer 1\n","[✔] Successfully built layer 1\n","Number of neurons: 1\n","Activation function: softmax\n","h10: 1.0\n","\n","[●] Backpropagating layer 1\n","[●] Backpropagating layer 0\n","[✔] Successfully evaluated data 2\n","[✔] Successfully evaluated batch 7\n"]}],"source":["# Input\n","model_json = Driver.load_model(model_file)\n","data_file = Driver.load_data(data_file)\n","\n","\n","# Reset index to ensure alignment after shuffling\n","data_file.reset_index(drop=True, inplace=True)\n","\n","# Preprocess data\n","X = data_file.drop(columns=['Species', 'Id'])\n","y = data_file['Species']\n","\n","# Encode categorical labels\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train = X_train.to_numpy()\n","y_train = y_train\n","\n","# Initialize FFNN\n","model = FFNN(model_json, X_train, y_train)\n","\n","# Build FNN\n","model.build()\n","\n","# Test the output\n","# model.test()\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ad693be4-3a1e-4be5-9f4f-9f4a320647d1' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"61f060aabad042bcb878ee344004af04","deepnote_persisted_session":{"createdAt":"2024-03-30T06:15:23.462Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
